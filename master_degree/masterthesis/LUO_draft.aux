\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Table of contents}{i}{section*.1}}
\@writefile{toc}{\contentsline {chapter}{List of figures}{iii}{section*.3}}
\@writefile{toc}{\contentsline {chapter}{List of tables}{v}{section*.5}}
\citation{bishop2006pattern}
\citation{krizhevsky2012imagenet}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Machine Learning for Classification}{1}{section.1.1}}
\citation{menard2002applied}
\citation{cortes1995support}
\citation{vapnik2000nature}
\citation{hornik1989multilayer}
\citation{scholkopf2001learning}
\citation{barutcuoglu2006hierarchical}
\citation{diplaris2005protein}
\citation{chen2012composite}
\citation{bo2014quasi}
\citation{hu2001quasi}
\citation{chen2010local}
\citation{chen2010local}
\citation{hu2001quasi}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Related Methods}{3}{section.1.2}}
\citation{zhang2006svm}
\citation{cheng2010efficient}
\citation{li2014growing}
\citation{bo2014quasi}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Unsupervised learning method}{4}{subsection.1.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Semi-supervised learning method}{4}{subsection.1.2.2}}
\citation{li2015geometric}
\citation{bengio2013representation}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Supervised learning method}{5}{subsection.1.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Motivation}{5}{section.1.3}}
\newlabel{mark:dectect_linear}{{1}{5}{Motivation}{remark.1}{}}
\newlabel{mark:numM}{{2}{5}{Motivation}{remark.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Thesis Organization}{6}{section.1.4}}
\citation{vapnik2000nature}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Quasi-linear Support Vector Machines}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch2}{{2}{7}{Quasi-linear Support Vector Machines}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Support Vector Machine}{7}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Support Vector Machine Optimization}{8}{subsection.2.1.1}}
\newlabel{eq2.5}{{2.5}{8}{Support Vector Machine Optimization}{equation.2.1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Illustration of a hyperplane and maximum margin for a SVM\relax }}{9}{figure.caption.7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fg:SVs}{{2.1}{9}{Illustration of a hyperplane and maximum margin for a SVM\relax }{figure.caption.7}{}}
\newlabel{eq:2:SVM_Primal}{{2.7}{9}{Support Vector Machine Optimization}{equation.2.1.7}{}}
\newlabel{eq:2:SVM_dual}{{2.11}{10}{Support Vector Machine Optimization}{equation.2.1.11}{}}
\newlabel{eq:2:SVM_dual_final}{{2.13}{10}{Support Vector Machine Optimization}{equation.2.1.13}{}}
\citation{jolliffe2002principal}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Kernel Function}{11}{section.2.2}}
\newlabel{fg:orignal_data}{{2.2(a)}{11}{Subfigure 2 2.2(a)}{subfigure.2.2.1}{}}
\newlabel{sub@fg:orignal_data}{{(a)}{11}{Subfigure 2 2.2(a)\relax }{subfigure.2.2.1}{}}
\newlabel{fg:transformated_data}{{2.2(b)}{11}{Subfigure 2 2.2(b)}{subfigure.2.2.2}{}}
\newlabel{sub@fg:transformated_data}{{(b)}{11}{Subfigure 2 2.2(b)\relax }{subfigure.2.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Visual kernel mapping\relax }}{11}{figure.caption.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces A comparison of linear SVM and nonlinear SVM on synthetic datasets.\relax }}{11}{figure.caption.9}}
\newlabel{fig:SVM_boundary}{{2.3}{11}{A comparison of linear SVM and nonlinear SVM on synthetic datasets.\relax }{figure.caption.9}{}}
\citation{scholkopf2001learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Definition of Kernel Function}{12}{subsection.2.2.1}}
\newlabel{eq:2:SVM_dual_Kernel}{{2.16}{13}{Definition of Kernel Function}{equation.2.2.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Positive Definite Kernel Function}{13}{subsection.2.2.2}}
\citation{bo2014quasi}
\citation{chen2010local}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Quasi-Linear Support Vector Machine}{14}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Mathematical Model of Quasi-Linear Support Vector Machine}{14}{subsection.2.3.1}}
\newlabel{eq:2.18}{{2.18}{14}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.18}{}}
\newlabel{eq:2.19}{{2.19}{14}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.19}{}}
\citation{moody1989fast}
\citation{bo2014quasi}
\newlabel{eq:20}{{2.20}{15}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.20}{}}
\newlabel{eq:2.21}{{2.21}{15}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.21}{}}
\newlabel{eq:2.22}{{2.22}{15}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.22}{}}
\newlabel{eq:2.23}{{2.23}{15}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Multiple local linear classifiers with interpolation for nonlinear separation hyperplane.\relax }}{15}{figure.caption.10}}
\newlabel{fg:visual_QLSVM}{{2.4}{15}{Multiple local linear classifiers with interpolation for nonlinear separation hyperplane.\relax }{figure.caption.10}{}}
\newlabel{eq:2.24}{{2.24}{16}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.24}{}}
\newlabel{eq:2.25}{{2.25}{16}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.25}{}}
\newlabel{eq:2.26}{{2.26}{16}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.26}{}}
\newlabel{eq:2.27}{{2.27}{16}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.27}{}}
\newlabel{eq:2.28}{{2.28}{16}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.28}{}}
\newlabel{eq:2.29}{{2.29}{16}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.29}{}}
\newlabel{eq:2.30}{{2.30}{16}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.30}{}}
\newlabel{eq:2.31}{{2.31}{17}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.31}{}}
\newlabel{eq:2.32}{{2.32}{17}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.32}{}}
\newlabel{eq:2.33}{{2.33}{17}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.33}{}}
\newlabel{eq:2.34}{{2.34}{17}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.34}{}}
\newlabel{eq:2.35}{{2.35}{17}{Mathematical Model of Quasi-Linear Support Vector Machine}{equation.2.3.35}{}}
\citation{bo2014quasi}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Quasi-Linear Kernel}{18}{subsection.2.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Quasi-linear kernel function adjust the number of local linear classifiers.\relax }}{18}{figure.caption.11}}
\newlabel{fg:QLSVM_M}{{2.5}{18}{Quasi-linear kernel function adjust the number of local linear classifiers.\relax }{figure.caption.11}{}}
\citation{bo2014quasi}
\citation{bo2014quasi}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Different type of basis threshold functions.\relax }}{19}{figure.caption.12}}
\newlabel{fg:basis_function_types}{{2.6}{19}{Different type of basis threshold functions.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {A nonlinear separation data set}}}{19}{figure.caption.12}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {An illustration of KPCA feature transformation}}}{19}{figure.caption.12}}
\newlabel{eq:2.36}{{2.36}{19}{Quasi-Linear Kernel}{equation.2.3.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Localization of Feature Space}{19}{subsection.2.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Modified k-means method on an artificial data set.\relax }}{20}{figure.caption.13}}
\newlabel{fg:kmeans_QLSVM}{{2.7}{20}{Modified k-means method on an artificial data set.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Proximity plot for a 10-class handwritten digit classification task.\relax }}{20}{figure.caption.14}}
\newlabel{fig:proximity-plot}{{2.8}{20}{Proximity plot for a 10-class handwritten digit classification task.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Local Linearity Extraction Based on Samples Space Division}{23}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Implementation Framework}{24}{section.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The framework of the proposed method .\relax }}{25}{figure.caption.15}}
\newlabel{fg:RF_frame}{{3.1}{25}{The framework of the proposed method .\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The extract condition of linear information in leaf nodes .\relax }}{25}{figure.caption.16}}
\newlabel{fg:linear_extract_cond}{{3.2}{25}{The extract condition of linear information in leaf nodes .\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The extract linear information at leaf nodes which are linear classifiers.\relax }}{25}{figure.caption.16}}
\newlabel{fg:visual_extracted_linear_info}{{3.3}{25}{The extract linear information at leaf nodes which are linear classifiers.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces The final quasi-linear SVM trained by random forest. \relax }}{26}{figure.caption.17}}
\newlabel{fg:QLSVM_byRF}{{3.4}{26}{The final quasi-linear SVM trained by random forest. \relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces The final quasi-linear SVM trained by random forest compare with random forest predict result.\relax }}{27}{figure.caption.18}}
\newlabel{fg:QLSVM_RF_compare}{{3.5}{27}{The final quasi-linear SVM trained by random forest compare with random forest predict result.\relax }{figure.caption.18}{}}
\citation{breiman:1984}
\citation{quinlan:1993}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Flow diagram of training process\relax }}{28}{figure.caption.19}}
\newlabel{fg:QLSVM_training_flow}{{3.6}{28}{Flow diagram of training process\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Flow diagram of testing process\relax }}{28}{figure.caption.20}}
\newlabel{fg:QLSVM_testing_flow}{{3.7}{28}{Flow diagram of testing process\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Tree Structured Models}{28}{section.3.2}}
\newlabel{algo:prediction}{{0}{30}{Tree Structured Models}{definition.4}{}}
\newlabel{fig:3:tree}{{3.8(a)}{31}{Subfigure 3 3.8(a)}{subfigure.3.8.1}{}}
\newlabel{sub@fig:3:tree}{{(a)}{31}{Subfigure 3 3.8(a)\relax }{subfigure.3.8.1}{}}
\newlabel{fig:3:partition}{{3.8(b)}{31}{Subfigure 3 3.8(b)}{subfigure.3.8.2}{}}
\newlabel{sub@fig:3:partition}{{(b)}{31}{Subfigure 3 3.8(b)\relax }{subfigure.3.8.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Splitting Rules}{31}{subsection.3.2.1}}
\newlabel{def:loss-decrease}{{5}{32}{Splitting Rules}{definition.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces The relationship in entropy, Gini index and classification error rate\relax }}{32}{figure.caption.22}}
\newlabel{fig:3:toy:impurity:comparison}{{3.8}{32}{The relationship in entropy, Gini index and classification error rate\relax }{figure.caption.22}{}}
\citation{breiman:1984}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces evaluate the importance of features by random forest.\relax }}{33}{figure.caption.23}}
\newlabel{fig:RF_feature_importance}{{3.9}{33}{evaluate the importance of features by random forest.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Generation of Classification Trees}{34}{subsection.3.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Binary classification task.\relax }}{34}{figure.caption.24}}
\newlabel{fig:5:set}{{3.10}{34}{Binary classification task.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Decision tree learned from Figure\nobreakspace  {}\ref  {fig:5:set}.\relax }}{34}{figure.caption.24}}
\newlabel{fig:5:tree}{{3.11}{34}{Decision tree learned from Figure~\ref {fig:5:set}.\relax }{figure.caption.24}{}}
\citation{schulter2015fast}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Array representation of the decision tree in Figure\nobreakspace  {}\ref  {fig:5:tree}.\relax }}{35}{table.caption.25}}
\newlabel{table:tree-array}{{3.1}{35}{Array representation of the decision tree in Figure~\ref {fig:5:tree}.\relax }{table.caption.25}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Local Linearity Extraction Based on Decision Tree }{35}{section.3.3}}
\newlabel{eq3.1}{{3.2}{36}{Local Linearity Extraction Based on Decision Tree}{equation.3.3.2}{}}
\newlabel{eq3.2}{{3.3}{36}{Local Linearity Extraction Based on Decision Tree}{equation.3.3.3}{}}
\citation{knuth1992problem}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Binary partitions of $L_t$ on the ordered variable $X_j$. Setting the decision threshold $v$ to any value in $[v_k,v_{k+1}]$.\relax }}{37}{figure.caption.26}}
\newlabel{fig:3:split_ordered}{{3.12}{37}{Binary partitions of $L_t$ on the ordered variable $X_j$. Setting the decision threshold $v$ to any value in $[v_k,v_{k+1}]$.\relax }{figure.caption.26}{}}
\newlabel{algo:findsplit}{{0}{38}{Local Linearity Extraction Based on Decision Tree}{equation.3.3.5}{}}
\newlabel{algo:best-split-line4}{{4}{38}{Local Linearity Extraction Based on Decision Tree}{equation.3.3.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}A Random Forest Framework}{38}{section.3.4}}
\citation{breiman2001random}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Ensemble Learning Methods}{39}{subsection.3.4.1}}
\newlabel{eq:3.6}{{3.6}{39}{Ensemble Learning Methods}{equation.3.4.6}{}}
\citation{krogh1995neural}
\citation{breiman1996bagging}
\citation{kohavi1996bias}
\citation{krogh1995neural}
\citation{breiman2001random}
\newlabel{eq:3.7}{{3.7}{40}{Ensemble Learning Methods}{equation.3.4.7}{}}
\newlabel{eq:3.8}{{3.8}{40}{Ensemble Learning Methods}{equation.3.4.8}{}}
\citation{breiman1996bagging}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Random Forest}{41}{subsection.3.4.2}}
\newlabel{eq:3.9}{{3.9}{41}{Random Forest}{equation.3.4.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces A comparison of classification boundaries of a several classifiers on synthetic datasets.\relax }}{42}{figure.caption.27}}
\newlabel{fig:SVM_RF_boundary}{{3.13}{42}{A comparison of classification boundaries of a several classifiers on synthetic datasets.\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Cluster Local Linear Partitions}{43}{subsection.3.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces Show characteristics of different clustering algorithms. \relax }}{44}{figure.caption.28}}
\newlabel{fig:cluster_comparision}{{3.14}{44}{Show characteristics of different clustering algorithms. \relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces Proposed method handle with non-linear data set\relax }}{44}{figure.caption.29}}
\newlabel{fig:cluster_linear_info}{{3.15}{44}{Proposed method handle with non-linear data set\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces Proposed method choose variable number of local linear classifiers after training random forest.\relax }}{45}{figure.caption.30}}
\newlabel{fig:cluster_M_number}{{3.16}{45}{Proposed method choose variable number of local linear classifiers after training random forest.\relax }{figure.caption.30}{}}
\citation{chang2011libsvm}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experiments}{47}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Evaluation Metrics}{47}{section.4.1}}
\citation{asuncion2007uci}
\citation{wolberg1990multisurface}
\citation{horton1996probabilistic}
\citation{gorman1988analysis}
\citation{guvenir1997supervised}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}UCI Data Set}{48}{section.4.2}}
\newlabel{UCI}{{4.2}{48}{UCI Data Set}{section.4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Description of the data sets\relax }}{49}{table.caption.31}}
\newlabel{table:1.1}{{4.1}{49}{Description of the data sets\relax }{table.caption.31}{}}
\citation{barutcuoglu2006hierarchical}
\citation{elisseeff2001kernel}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces The classification accuracies of SVM with different kernels and RF\relax }}{50}{table.caption.32}}
\newlabel{table:1.2}{{4.2}{50}{The classification accuracies of SVM with different kernels and RF\relax }{table.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Yeast Gene Data Sets}{51}{section.4.3}}
\newlabel{Yeast}{{4.3}{51}{Yeast Gene Data Sets}{section.4.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Yeast Data Set Description\relax }}{51}{table.caption.33}}
\newlabel{tabledescription}{{4.3}{51}{Yeast Data Set Description\relax }{table.caption.33}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Classification results on the Yeast Gene Data Sets\relax }}{52}{table.caption.34}}
\newlabel{tableyeast}{{4.4}{52}{Classification results on the Yeast Gene Data Sets\relax }{table.caption.34}{}}
\bibstyle{IEEEtran}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusions}{53}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibdata{LUOreference}
\bibcite{bishop2006pattern}{1}
\bibcite{krizhevsky2012imagenet}{2}
\bibcite{menard2002applied}{3}
\bibcite{cortes1995support}{4}
\bibcite{vapnik2000nature}{5}
\bibcite{hornik1989multilayer}{6}
\bibcite{scholkopf2001learning}{7}
\bibcite{barutcuoglu2006hierarchical}{8}
\bibcite{diplaris2005protein}{9}
\bibcite{chen2012composite}{10}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{55}{section*.35}}
\bibcite{bo2014quasi}{11}
\bibcite{hu2001quasi}{12}
\bibcite{chen2010local}{13}
\bibcite{zhang2006svm}{14}
\bibcite{cheng2010efficient}{15}
\bibcite{li2014growing}{16}
\bibcite{li2015geometric}{17}
\bibcite{bengio2013representation}{18}
\bibcite{jolliffe2002principal}{19}
\bibcite{moody1989fast}{20}
\bibcite{breiman:1984}{21}
\bibcite{quinlan:1993}{22}
\bibcite{schulter2015fast}{23}
\bibcite{knuth1992problem}{24}
\bibcite{breiman2001random}{25}
\bibcite{krogh1995neural}{26}
\bibcite{breiman1996bagging}{27}
\bibcite{kohavi1996bias}{28}
\bibcite{chang2011libsvm}{29}
\bibcite{asuncion2007uci}{30}
\bibcite{wolberg1990multisurface}{31}
\bibcite{horton1996probabilistic}{32}
\bibcite{gorman1988analysis}{33}
\bibcite{guvenir1997supervised}{34}
\bibcite{elisseeff2001kernel}{35}
