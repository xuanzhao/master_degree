\documentclass[senior]{IPSstyle}

  \Year{2014}
  \Month{January 10}
  \Author{44121591-3: LUO,Yongxin}

  \Title{Enhanced Differential Evolution by Clearing Niching Method}

  \Advisor{Professor Furuzuki}

\usepackage{amssymb,amsmath}

\usepackage{mathptmx}
\usepackage{helvet}
\usepackage{courier}
\usepackage{type1cm}

\usepackage{makeidx}
\usepackage{graphicx,subfigure}
\usepackage{multicol}
\usepackage{multirow}
\usepackage[bottom]{footmisc}

\usepackage{mathrsfs}
\usepackage{amssymb,amsmath}
\usepackage{amsfonts}
\usepackage{color}
\usepackage{CJKutf8}

\usepackage{listings}
\usepackage{algorithm,algorithmicx,algpseudocode}
\usepackage[toc,page,title,titletoc,header]{appendix}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

  \Abstract{
Handing multimodal functions in continuous space is a very important and challenging task in evolutionary computation community, especially when most of the real-world applications exhibit highly multimodal landscapes with very high dimensions. To search global optimal of upon functions, we use Differential Evolution (DE) algorithm, which is a simple and powerful population-based stochastic search technique. While DE still face the problem of premature convergence during the iterations.

Motivated by the dynamics and the proximity characteristics of DE's mutation strategies, which always pointing to the direction of evolution, we propose a clearing niching mutation strategy respectively combined with two methods, Boltzmann scheme and self-adaptive parameter control. The niching method is presented to avoid the premature phenomenon in DE, aiming to maintain the diversity of evolution in each generation, which prevent the convergence to local optima. Clearing niching mutation strategy with Boltzmann scheme tend to realize a balance searching by finding the efficient individuals of niches in each generation. Besides, clearing niching mutation strategy with a two-layered DE for self-learning parameters are proposed to eliminate the time in finding proper parameters.


Both two proposed modifications are tested on commonly used benchmark problems for unconstrained optimization. Experimental results with some state-of-art algorithms indicate that the proposed mutation strategy is competitive and very promising. It improves the efficiency and robustness of the algorithm.

}

\Keywords{Differential Evolution, mutation strategy, niching method, balance searching, parameter control}

\Acknowledgments{
   It is quite memorable time I spend in here, Furuzuki Lab, Waseda University. I dearly gratitude our professor, Jinglu HU, who devoting himself to supervising us. Living and studying in foreign country for the first time is not an easy task to fulfill, professor HU always give helpful and appropriate suggestions on how to handle those problems with his breadth of mind.
   
   Thanks my professor Tao Yang in Xiamen University, who recommends me to Waseda University and gives me great support to complete my study in Japan, which is an amazing life experience.

   I would also like to thank Sheng Huang, Dongcheng Wu, Chenglong Hu, Yong Fu, who have provided their valuable suggestions and assistance to me in this research.

   Thanks all my friends and families for your great support and companion, this paper can not be finished without your patient to comfort me.
   
   

}


\begin{document}

 \makepreliminarypages
 \singlespace
 \frontmatter
 \tableofcontents
 \listoffigures
 \listoftables
 \mainmatter
 \clearemptydoublepage
 \setlength{\baselineskip}{23.0pt}

\chapter{Introduction}

Differential evolution (DE), is a well-known simple yet powerful population-based stochastic search technique\cite{storn1997differential}, which is an efficient and effective global optimizer in the continuous searching domain. Since it has presented good convergence and easy modeling features in many real-world cases, DE has been widely studied on its performance improvements and its applications to complicated problems in recent years.

\section{Background and Motivation}


The niching method is presented to avoid the premature phenomenon in Differential Evolution, aim to maintain the diversity of evolution in each generation, which prevent the convergence to local optima.A niche is commonly referred to an optimum of the domain, the fitness representing the resources of that niche\cite{mahfoud1995niching}\cite{liu2007optimal}, this definition is brought from biology and first used in genetic algorithm (GA). The niching method is presented to avoid the premature phenomenon in DE, aim to maintain the diversity of evolution in each generation, which prevent the convergence to local optima\cite{li2002species}. The clearing procedure proposed by Petrowski.A is one of a niching method inspired by the sharing niching method: the sharing of limited resources within sub-populations of individuals characterized by some similarities\cite{epitropakis2013dynamic}.

Clearing niching has been constantly used to keep balance between several subpopulation, a clearing procedure in estimation of distribution algorithm (EDA) is proposed to cluster niches (subpopulation) then selectively choose dominate individuals in order to maintain diversity. Not only in EDA, Michael G inadopt niching method in DE mutation strategy for multimodal optimization problems.

The clearing procedure is one of a niching method inspired by the sharing niching method: the sharing of limited resources within subpopulations of individuals characterized by some similarities\cite{de1975analysis}. Instead of evenly sharing the available resources among the individuals of a subpopulation, the clearing procedure supplies these resources only to the best individuals of each subpopulation. By finding the efficient individuals of niches in each generation, we may speed up the convergence. The clearing is naturally adapted to elitist strategies, which can significantly improve the performance of evolution.\\

1) $Niching \:with\: Balance\: searching$

Since convergence speed is also highly relevant with premature problems, we need a method to control the speed of convergence and realize a balance searching procedure.  When searching for a global optima in difficult situation, a reasonable procedure is: at first searching area as large as possible, as iteration goes on the searching should be as detail as it can. Boltzmann Scheme is proposed to realize this procedure and combine with clearing niching method, we adapt the Boltzmann method in mutation strategy.

A balance searching procedure is tuned by the Boltzmann weight, at the beginning phase of searching, the dominating novelty-proportionate selection can guide the DE searching to cover the search space as much as possible. At the end phase of searching, the dominating fitness proportionate selection can enforce the searching to exploit more promising areas.

Motivated by the dynamics and the proximity characteristics of Differential Evolution's mutation strategies tending to distribute the individuals of the population to the vicinity of the problem's minima, we propose a new Differential Evolution mutation strategy which combine niching method with Boltzmann scheme.\\

2) $Niching\: with\: Parameter\: control$

Parameters study has become one of the most significant research on DE, which includes the population size NP, amplification factor F and crossover rate CR. Over past decades, researchers have been investigating ways of improving the ultimate performance of DE algorithm by tuning its control parameters\cite{brest2009dynamic}. According to Storn and Price, DE is much more sensitive to the choice of F than CR\cite{storn1997differential}. Hence, Gamperle et al. reported that choosing the proper control parameters for DE is more difficult than expected\cite{gamperle2002parameter}.


In order to eliminate the time consuming task in fine-tuning control parameters in DE, and to avoid adding too many parameters, we propose a two-layered DE (TLDE) with self-adaptive control parameters based on the previous performance. The TLDE composes of two DE layers: a top DE layer and a bottom DE layer. The top DE layer is a simplified DE without crossover operation, for control parameter adaptation. The bottom DE layer is a doubled, parallel DE with two set control parameters, for the basic evolution task.

There is a natural assumption that in a DE, better control parameters are more likely to generate better offspring to survive, which will also change with different regions during iteration process. However, due to the stochastic characteristics of DE, it is hard to evaluate and then select better control parameters in only one generation. Differ from other greedy strategies which self-adapting parameters by every generation, in this paper a new scheme is introduced, which is designed to evaluate and select good control parameters over a learning period consisting of $L_p$ generations.\\

Follow the idea to combine parameter control adaptation and diversity maintenance, in the second part of this paper we introduce a clearing niching method to improve the performance of the TLDE. For the purpose of construct an effective and robust DE for the solution of different types of optimization problems, we employ a niching mutation strategy to enhance the TLDE. A complete system is formed with the combination of two-layer learning parameters.

\section{Organization of the thesis}
The remainder of this paper is structured as follows: Section \uppercase\expandafter{\romannumeral2}  describes algorithms used in this paper and some related work. In Section \uppercase\expandafter{\romannumeral3}, we describe the proposed method, which describe the structure and mechanism of TLDE enhanced with clearing niching method. To evaluate the first proposed algorithm and testify its effectiveness, Section \uppercase\expandafter{\romannumeral4} runs the second proposal and shows the experiment result several simulations. The paper ends in Section\uppercase\expandafter{\romannumeral5} with conclusions on contributions of this work.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Chapter 3
\chapter{Related Work} \label{ch3}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Chapter 3

\section{Niching Method}

Niching methods is designed for improving the procedure of locating the optimum of multimodal functions. It aims to maintaining population diversity and permit the genetic algorithm searching multiple optimums at the same time\cite{mahfoud1995niching}. A niche is a concept from biology, can be treat as a subspace in the environment that can support different types of life. When searching global optimum during evolution, different individuals with fitness value can be viewed as different species.

A specie is defined as a group of individuals with similar biological features, different species has low probability to cultivate each other, one specie classified as one niche\cite{spears1994simple}. For each niche,  the physical resources are finite and should be shared by the individuals of that niche. By analogy, niching methods tend to achieve a natural emergence of niches and species in the searching space\cite{chen2010adaptive}. The similarity and difference between each niche can be divided by distance of individuals, and the way of calculating the distance also shows different ways to cluster niches.

The clearing, sharing, and crowding method is probably the best known and most widely used among niching techniques. In the following subsections, we will introduce these methods and discuss the reason we only adopt clearing niching method in this paper.

\subsection{Clearing Niching Method}

Niching method is designed to overcome the premature convergence problem due to the loss of diversity. The mechanism of maintain diversity in niching method is keeping several sub-populations within search space during iteration. Since niching method proposed from $1995$\cite{mahfoud1995niching}, various niching techniques derived from it. This paper gives a short introduce of clearing niching method which is nearly as others.\\

$1)\:Principles$%

A clearing niche is characterized by a limited amount of resources available for living individuals which share commonalities. Instead of sharing the available resources among all individuals of a subpopulation, which is widely used, the clearing niching means only few best members in each subpopulation possess the limited resources\cite{sareni1998fitness}. Each subpopulation contains a dominant individual which has the best fitness. The dissimilarity of the individuals with the dominate one is less than a given threshold, which is the clearing radius $\delta$.

The original clearing algorithm preserves the individual with best fitness, and resets other individuals of that subpopulation to zero. Hence, the clearing niching gives the whole resource of a niche to a single individual, which is called the winner. This winner takes all the resources of the subpopulation instead of sharing with each other.

Moreover, the life coexistence is widely acknowledged, for a given niche, the numbers of winners rarely to be one. Several winners with best fitness coexist in the same subpopulation and kick out those losers, who will fail to generate offspring and stop in the middle of evolution. The capacity of a niche is defined as the maximum number of winners that this niche can accept. Notice that if a capacity greater than 1 is chosen, then the set of winners for a given population is not generally unique.

An elitist strategy memorizes the best individuals of a population found before the application of genetic operators and inherit them to the next generation. \\

%=============================================================================
$2)\:Procedure$

At first, sort population NP according to the fitness of the individuals by decreasing order, for choosing the winners. The whole population is ranked for the sake of clarity in this version of the algorithm. A more optimized algorithm would sort only the dominant individuals, which we will referred to in the next chapter. Then, calculate the distance between two individuals i and j from the population. To mention that, this distance can be Euclidean distance, hamming distance or any other distance, its only a measurement to test the intimacy between each other, and varies from different occasions. And then, choose the winners follow the order from best fitness, and reset those individuals who are too close to the winners. At last return the set of winners with their fitness value.

For better understanding, a brief pseudo code of clearing procedure is presented (Algorithm \ref{algorithm1}). Take population
$\{X_{1,2,\dots,NP}^g\}$ in $g^{th}$ generation and radius $\delta$ as input, we can get the winner set$\{X_c^g\}$ of this iteration.

\begin{algorithm}
\renewcommand{\arraystretch}{0.6}
\caption{Clearing Procedure}
\begin{algorithmic}[1]
\Require clearing radius $\delta$, population $\{X_{1,2,\dots,NP}^g\}$
\Ensure winners set $\{X_c^g\}$, number of winners $n$
\Function {Clearing}{$\delta$, $X_i^G$}
\State Sort fitness $f(X_{1,2,\dots,NP}^g)$
\For{$i=1\to NP$}
    \If{fitness $f(X_i^g)> 0$}
    \State $\{X_c^g\} \gets X_i^g$
    \State /*\textbf{Save the winner} of this niche*/
    \For{$j=i+1 \to NP$}
        \If{distance $(X_i^G,X_j^g)\leq \delta$}
            \State fitness $f(X_j^g) \gets 0$
            \State /*\textbf{Clear others} of this niche*/
        \EndIf
    \EndFor
    \EndIf
\EndFor
\EndFunction
\end{algorithmic}
\label{algorithm1}
\end{algorithm}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Sharing Niching Methods}

Petrwoski's clearing method, Goldberg's sharing function approach are the most popular approaches that have been proposed by the evolution field\cite{sareni1998fitness}. The sharing method is also widely used niching method. We mention the sharing niching method here to compare with clearing, that these two methods can realize the same effect, while in cases of this paper, clearing method is preferred.

From a similar starting point that, the expected number of offspring of an individual $i$ is proportional to fitness which is shared by other individuals in a certain niche. The equation of the operator will be described as:

\begin{equation}
\hat{f_i^g}=\frac{f_i^g}{\sum\limits_{j=1}^n sh(d_{ij})}
\end{equation}

where sharing function is calculated by:

\begin{equation}
sh(d)=\left\{
\begin{array}{ll}
1-(\frac{d}{\sigma_{share}})^\alpha \quad \text{if} d< \sigma_{share} \\
0 \quad \text{otherwise}
\end{array}
\right.
\end{equation}

where $d_{ij}$ is the distance between individual i and j, $\sigma_{share}$ represents the radius of niche, and $\alpha$ always set to 1 as a constant value.

Consider the hypothesis where all the individuals of a subpopulation x have a fitness almost equal to a value $f(x)$, which represent the niche and are at a distance very close to each other. This particular case typically occurs at the steady state when subpopulation are located on the highest maxima of the function. Also in high dimension space, the Euclidean distance is close to zero. Assume that individual i belongs to subpopulation x, a new expression of $\hat{f}$ is obtained:

\begin{equation}
\hat{f_i^g}\approx \frac{f_i}{N_x^g}\approx \frac{f(x)}{N_x^g}
\end{equation}
where $N_x^g$ is the number of individuals in the $x$-th niche at the $g$-th generation. The expected number of offspring of an individual i at generation g is:

\begin{equation}
E({n_i^{sharing}}^g)=n\frac{\hat{f}_i^g}{\sum\limits_{j=1}i \hat{f}_j^g}\approx \frac{n}{N_x^g}\frac{f(x)}{\sum\limits_{y=1}^cf_y}
\end{equation}

The expected number of individuals E that belong to subpopulation x is obtained by multiplying equation upon by $N_x^g$:

\begin{equation}
E({n_x^{sharing}}^g)\approx n \frac{f(x)}{\sum\limits_{y=1}^cf_y}\approx E({n_i^{sharing}}^g)\times N_x^g
\end{equation}
With the sharing method, if a subpopulation contains more individuals than expected due to the selection noise at a given generation, each of them will have offspring which is expected less than 1 in order to restore the equilibrium.

While in the stochastic universal selection procedure, an individual of such a subpopulation could not have offspring. In this case, the losers of the subpopulation will be disappeared. This phenomenon can be countered with a large enough number of individuals for each desirable subpopulation when the survival probability is high, which implies an adequate dimensioning of the population.

\subsection{Clearing v.s. Sharing method}

The clearing niching associated with an stochastic selection procedure ensure the number of offspring of the winners of a subpopulation, which is always greater or equal to the fitness of others. Consequently this subpopulation survives with certainty, and the clearing method gives a lower bound to the population size wihich is smaller than the one required by the sharing method. \cite{petrowski1996clearing}Therefore, the clearing niching method is more efficient we choose to use in this paper, instead of sharing method, follows the properties below:

1. The complexity of the clearing procedure is lower than that of the sharing method.

2. The clearing is directly compatible with elitist strategies, which can be used to both unimodal and multimodal functions.

3. The behavior of the genetic algorithm with the clearing procedure can be controlled between that of the maximum clearing and that without clearing by setting the niche capacity to an appropriate value.

4. The genetic drift due to the selection noise is significantly reduced with stochastic universal selection, which used by DE, and the populations may be far smaller than those required by the sharing method.


\section{DE with niching method}

Few algorithms have been proposed in the literature of DE, which attempt to optimize real world problems. Niching algorithms usually impose a restrictive reproduction technique which means to maintain the diversity of their populations and converge efficiently. Following two subsections describe two kind of niching methods adapted in DE at present.

\subsection{Adaptive population DE by niching}

This kind of niching method used to keep population diversity and expand search to accelerate convergence, also with self-adaptive niching radius during the evolution. By using an extra population set choosing by sharing niching method\cite{liu2007optimal}\cite{lin2002niche}.

In the process of niching, the radius will vary with population convergence. While the population is sparse and scattered, the niche radius should be large enough to maintain the species diversity, while the population is concentrated, the niche radius should be relatively small to ensure the number of niches. Despite the other steps of niching, the radius is defined as follow:

\begin{equation}
\begin{array}{llll}
R_{ch}=R_{max}\cdot exp(-\phi\cdot \frac{l-d_{avg}}{l})\\
R_{max}=R_0\cdot l\\
d_{avg}=\frac{2}{n(n-1)}\sum\limits_{i=1}^{N-1}\sum\limits_{j=i+1}^Nd(X_i-X_j)\\
l=sqrt{\sum\limits_{j=1}^n(x_{jmax}-x_{jmin})^2}.
\end{array}
\end{equation}
Where $R_{max}$ is the maximum of radius, $\phi$ is the adjustment parameter, $d_{avg}$ is the average distance between individuals, $R_0$ is the proportion parameter of niching radius, $l$ is the diagonal in N dimensional search space.

A niche eliminating mechanism also involved, merging M optimal individuals together from parent, and descendants to produce the competition population $S$ carrying $N+M$ individuals. The distance between individuals which beyond the competition population is calculate by:

\begin{equation}
\lvert\lvert X_i-X_k\rvert\rvert=\sqrt{\sum\limits_{j=1}^n(x_{ij}-x_{kj})^2}
\end{equation}
where $i=1,2,\dots,N+M-1$, $k=i+1, i+2,\dots, N+M$. From competitions among similar individuals of the competition population that the distance between them in the search space is less than a dissimilarity threshold, the losers fitness is greatly decreased by imposed penalty function and the winners remain unchanged.

This operation not only retains optimal individuals of the parent population which can improve the convergence rate, but also make individuals maintain a certain distance keeping the population diversity. This mechanism is adopted to accelerate convergence speed and avoid similar individuals, which can greatly raise the searching efficiency of algorithm. And the adaptive idea of niching will be borrowed in our proposed method in a different way.

\subsection{Crowding DE for multiple optimal function}

Highly multimodal landscapes with multiple local and global optimal represent common features in real world\cite{epitropakis2011finding}. To locate and maintain a large number of global solutions, a control parameter adaptation technique and a external dynamic archive. This kind of method aim to locate as many global optima as possible when a multimodal function is obtained\cite{yin1993fast}\cite{thomsen2004multimodal}. The main idea is to change the target vector in mutation strategy by niching method, which maintain the species varying from different area.

In this case, each individual is evolved by using its nearest neighbor individual and random vector differences in an attempt to keep the individual within the vicinity of an optimum and simultaneously to explore effectively the search space. Given a population NP, at the $g$-th generation, the mutation strategy will evolve each individual $x_g^i$, $i=1,2,\dots,NP$, to generate the mutant individual $v_{g+1}^i$ according to the following equation:

\begin{equation}
v_{g+1}^i=x_g^{NN_i}+F(x_g^{r_1}-x_g^{r_2})
\end{equation}

where $x_g^{NN_i}$ is the spatial nearest neighbor of the current individual $x_g^i$, $F>0$ is the mutation factor, and $r_1, r_2$ are randomly chosen indexes ($r_1, r_2\in \{1,2,\dots,NP\}$).

By this kind of recombination, which mainly responsible for the diversity of the population, to improper select the value of populations during evolution and dynamic elite individuals with poor performance. Also, some approaches not only show the robust an stable behavior during evolution, but also reduce the influence of parameters sensitivity in DE.



\section{Differential Evolution}

DE is a novel population based on intelligent optimization algorithm which is easy to use and has the advantages of strong robustness, but its efficiency is limited an probably fall into local optimum because of loss of diversity, slowness of searching speed and premature when approaching the global optimum\cite{qin2009differential}. Also, its property of sensitive to parameters F and CR has been proved from former researchers\cite{salman2007empirical}. Aim to solve these two problems, we would fist introduce the work of former researchers, and motivated by their method to improve DE, we then introduce our proposed method in the next chapter. 

DE is a population based iterative optimization algorithm. Offspring are generated by perturbing the solutions with a scaled difference of selected population vectors, and update population by greedy strategy remains better individuals. Similar to Genetic Algorithms, DE process mutation, crossover and selection. Although it use the same concept of fitness in the selection, it devises its own crossover and mutation in the real continuous space, while GA is optimization for discontinuous space. \\

%=============================================================================
$1) \: Initialization$

Classic DE begins by randomly initializing a population of $NP$, $D$-dimensional vectors $X_i^g$,$i=1,2,\dots,NP$, which represent the candidate solutions and aim to achieve the global optimization of domain during evolution.

We denote generations $g\in \{0,1,\dots G\}$ in DE and the $i^{th}$ vector of the population at the current generation as%
\begin{equation}
X_i^g=[X_{i,2}^g,X_{i,2}^g,\dots X_{i,D}^g]
\label{eq1}
\end{equation}
where $i\in [1,N]$. Population size $NP$ should be at least four and unchanged during the searching process. The initial population is $X_i^0=[X_{i,1}^0,X_{i,2}^0,\dots,X_{i,D}^0]$ within the search space constrained by the minimum and maximum bounds, which varies from different situations: $X_{i,d}^{min},X_{i,d}^{max}$ where $1\leq d \leq D$. Hence the $d^{th}$ dimension of $i^{th}$ vector will be initialized as
\begin{equation}
 X_{i,d}^0= X_{i,d}^{min}+rand_{i,d}(0,1)\times( X_{i,d}^{max} X_{i,d}^{min})
 \end{equation}
where $rand_{i,d}$ is an independent value uniformly distributed between the range [0,1], in each dimension of the $i^{th}$ vector. During the evolution process, DE employs mutation, crossover and selection operations, which are described as follow subsections.\\

%=============================================================================
$2) \:Mutation$

After initialization procedure, DE creates a mutation vector $V_i^g$ by doing recombination with target vector $X_i^g$ for compare and evolution. In other words, differential mutation adds a scaled difference of randomly sampled vectors to a third vector.

The ``DE/current-to-rand/1'' mutation strategy is rotation invariant. This mutation strategy is always used in multiobjective optimization problems.

\begin{figure}[H]
\centering
\includegraphics[width=11cm]{DEmutation}
\caption{Mutation of conventional DE} \label{fig1}
\end{figure}

For each target vector $X_i^g$, a mutation vector $V_i^g$ is generated by the basic "rand/1/bin" strategy as shown in figure \ref{fig1}:%
\begin{equation}
V_i^g=X_{r_1}^g+F(X_{r_2}^g-X_{r_3}^g),\: r_1\neq r_2\neq r_3\neq i
\label{eq2}
\end{equation}
where $r_i$ is randomly chosen integers from $[1,NP]$. ``Amplification factor'' $F$ is one of key parameters in DE which affects step vector $(X_{r_2}^g-X_{r_3}^g)$.\\

%=============================================================================
$3) \:Crossover$

To complement the differential mutation search strategy, DE also employs uniform crossover to increase the potential diversity of the population. There are two kinds of crossover scheme\textemdash exponential and binomial. In binomial crossover, which is usually used, DE cross each target vector $X_i^g$ with mutation vector $V_i^g$ to form a trail vector $U_i^g$, which determined as:
\begin{equation}
U_{i,j}^g=\left\{%
\begin{array}{ll}V_{i,j}^g \quad \text{if}\:rand_{i,j} (0,1)\leq CR_{i,j} \:or \: j=j_{rand}\\
X_{i,j}^g \quad \text{otherwise}.
\end{array}
\label{eq3}
\right.
\end{equation}
$j=1,2,\dots,D$ and $rand_{i,j}$ is the $j^th$ evaluation of a uniform random number generator with outcome $\in[0,1]$. ``Crossover rate'' CR is another key parameter set as constant in conventional DE. CR is a user-defined value just like F, controls the probability of trail vector copied from mutation vector. $j_{rand}$ is a randomly generated integer from the range [1,D] to ensure that the trail vector does not duplicate $X_i^g$ in every dimension. To determine which source contributed the trail vector $U_i^g$ binomial crossover compare CR with a uniform random number $rand_{i,d}(0,1)$ for each dimension of mutation vector. If the random numbers is less than or equal to CR, the trail vector is inherited from the mutation vector $V_i^g$, otherwise, it is copied from the target vector $X_i^g$. (shown in figure\ref{fig2})
\begin{figure}[H]
\centering
\includegraphics[width=11cm]{DEcrossover}
\caption{Crossover of conventional DE} \label{fig2}
\end{figure}

In exponential crossover operation, the trail vector $U_i^g$ is inherited from mutation vector starting from the randomly chosen index $j_{rand}$. Then the trail vector continued to copy from mutation vector till $CR\ge rand(0,1)$. Then the remaining trail vectors $U_i^g$ are copied from the target vector $X_i^g$. In this paper, we only use binomial crossover which is widely used.\\

%=============================================================================

$4)\: Selection$

By completing to the fitness values, selection operation determines whether the target vector or the trail vector survives to the next generation. Choosing the survive one between target vector $X_i^g$ and trail vector $U_i^g$, greedy criterion is used as follow equation%
\begin{equation}
X_i^{g+1}=\left\{%
\begin{array}{ll}U_i^g \quad if \: f(U_i^g)<f(X_i^G)\\
X_i^g \quad otherwise.
\end{array}
\label{eq4}
\right.
\end{equation}
where $f(X_i)$ is the function to be minimized. Keep the population size as constant over subsequent generation, the object function value of trail vector $f(U_i^g)$ is compared to the corresponding value of target vector $f(X_i^g)$. If the trail vector $U_i^g$ has an equal or lower object function than that of its target vector $X_i^g$, it replaces the target corresponding target vector and survives in the next generation; otherwise, the target vector remain its place in the population.

The process of mutation, crossover and selection is repeated in every individual in each generation until the optimum is located, or a pre-specified termination criterion is satisfied and the individual with the best fitness value is reported as the solution (shown in figure \ref{fig3}).\\
\begin{figure}[H]
\centering
\includegraphics[width=11cm]{DEbasic}
\caption{Flowchart of Conventional DE} \label{fig3}
\end{figure}

$4) Discussion$

After the description of DE procedures, we can easily know that the mutation strategy is the most important step among others, former researchers have considered a lot of ways to deform this equation to make it more efficient. Nowadays, there are five mutation strategies are widely used:

\begin{equation}
``DE/rand/1":V_i^g=X_{r0}^g+F\times (X_{r1}^g-X_{r2}^g)
\end{equation}
\begin{equation}
``DE/rand/2":V_i^g=X_{r0}^g+F\times (X_{r1}^g-X_{r2}^g)+F\times (X_{r3}^g-X_{r4}^g)
\end{equation}
\begin{equation}
``DE/best/1":V_i^g=X_{best}^g+F\times (X_{r1}^g-X_{r2}^g)
\end{equation}
\begin{equation}
``DE/best/2":V_i^g=X_{best}^g+F\times (X_{r1}^g-X_{r2}^g)+F\times (X_{r3}^g-X_{r4}^g)
\end{equation}
\begin{equation}
``DE/target-to-best/2":V_i^g=X_i^g+F\times (X_{best}^g-X_i^g)+F\times (X_{r1}^g-X_{r2}^g)
\end{equation}
where $r_0$, $r_1$, $r_2$, $r_3$, $r_4$ are randomly chosen vector index from $N$ that is different from the target vector index, $i$. The scale factor, $F$ is a positive real number that controls the amplification of the randomly chosen differential vectors. $X_{best}^g$ is the best individual vector correspond to the best fitness in current generation.

It is worth to mention that the mutation strategies are named in the format $DE/x/y/z$, where DE stands for differential evolution obviously, $x$ denotes the vectors to be perturbed, $y$ represents the number of difference vectors considered for perturbation of $x$, and $z$ is the crossover type that used. Different strategies shows different characteristics when operating optimization:

Strategies relying on the best solution at present such as ``DE/best/1/bin'', ``DE/best/2/bin'' and ``DE/rand-to-best/1/bin'', always appeal time saving character in convergence, which also good at solving unimodal problems. However, they are more likely to premature convergence and limit to local optimal in complex multimodal problems.

Strategy with randomly choosing target vectors ``DE/rand/1/bin'' shows slower convergence than former mentioned ``best'' strategies, but bears stronger exploration capability. Therefore, for solving multimodal problems referred in this paper, we use this mutation strategy.

\section{DE with self-adaptive control parameters}

Although DE is a stochastic population based evolution algorithm, appropriate control parameters\textemdash amplification factor F and crossover rate CR, will bring good evolution efficiency and result in better solution. Therefore, choosing suitable control parameter values is, commonly, a problem dependent task\cite{brest2006self}\cite{brest2009dynamic}. In the conventional DE algorithm, the control parameters F and CR are constants during the evolution, while the setting for control parameters depends on problems. The trail-error method applied in tuning control parameters requires multiple optimization runs, which is obviously time consuming. Moreover, during the evolution of iteration, different population coupled with different parameter settings may be required in order to achieve the best performance, especially dealing with multimodal functions.

Therefore, researchers have developed several techniques to avoid manual tuning of the control parameters. For example, Janex Brest in summarizes a Self-adaptive DE algorithm with self-adaptive control parameters\cite{brest2006self}, in which each individual of generation is extended with parameters F and CR. Most of existing methods for parameter control concentrate on the probability to choose random parameters. But Qin $et\: al.$ proposed a Strategy adaptation DE (SaDE) algorithm\cite{qin2009differential}, in the SaDE both mutation strategies and control parameters can be gradually self-adapted according to their previous experiences of generating promising solutions.

On the other hand, although self-learning DE eliminates time for finding appropriate control parameters, it still faces the problem of premature convergence during evolution. A simple yet popular explanation for the occurrence of premature convergence is the loss of diversity, which also influences the system stability.

In the literature, a self-adaptive DE known as JADE was proposed by J. Zhang\cite{zhang2009jade} in  which implemented a mutation strategy ``DE/current-to-$p$-best'' diversifies the population but guarantee the fast convergence property at the same time. Similarly, Ref. describes a dynamic self-adapting parameter F and CR called jDE, combined with a multi-population method to increase diversity and stabilize the searching procedure.

This section briefly reviews some self-adaptive DE algorithms that using ``DE/rand/1/bin'' mutation strategy, which can combine with the niching method.

\subsection{Self-adaptive parameter(SDE)}

SDE algorithm was first brought out by Salman et al. the control parameters are initialized for each individual and generated through normal distribution\cite{salman2007empirical}.

It works as follows: for each target vector, $x_i^g$ in the $g$-th generation, offspring $x_i^{g+1}$ is created by randomly selecting three individuals from the current population, namely $x_{i_1}^g$, $x_{i_2}^g$ and $x_{i_3}^g$, with $i_1 \neq i_2 \neq i_3 \neq i$, and $i_1, i_2, i_4 \in U(1,2,\dots,s)$, where s is the population size. A random number, r, is then selected with $r\in U(1,2,\dots,N_d)$, where $N_d$ is the number of genes (parameters) of a single chromosome. Then, for all parameters $j=1,2,\dots,N_d$
\begin{equation}
x_{i,j}^{g+1}=\left\{
\begin{array}{ll}
x_{i_3,j}^g+F_i^g\cdot (x_{i_1,j}^g-x_{i_2,j}^g) \quad \text{if} U(0,1)\leq N(0.5,0.15) \text{or} j=j_{rand}\\
x_i^g \quad \text{otherwise}
\end{array}
\right.
\end{equation}
where
\begin{equation}
F_i^g=F_{i_4}^g+N(0,1)\times(F_{i_5}^g-F_{i_6}^g)
\end{equation}
with $i_4\neq i_5\neq i_6$ and $i_4,i_5,i_6 \in U(1,2,\dots,s)$.

Thus, each individual i has its own scaling factor $F_i$ which is a function of the scaling factor of randomly selected individuals. The parameter $F_i$ is first initialized for each individual in the population from a normal distribution, $N(0.5, 0.15)$, generating values which fits well within the range $(0,1]$.

\subsection{Self-adapting parameter(jDE)}

Brest et al. proposed a new adaptive DE, jDE, which is based on the classic mutation strategy ``DE/rand/1/bin''. Similar to other schemes, jDE fixes the population size during the optimization while adapting the control parameters $F_i$ and $CR_i$ associated with each individual. jDE regenerates new values for $F_i$ and $CR_i$ according to uniform distributions with probabilities.

Control parameters are updated as follows:
\begin{equation}
F_i=\left\{
\begin{array}{ll}
rndreal_i[0,1]\quad rndreal[0,1]<\tau_1\\
F_i \quad \text{otherwise}
\end{array}
\right.
\end{equation}
\begin{equation}
CR_i=\left\{
\begin{array}{ll}
rndreal_i[0,1]\quad rndreal[0,1]<\tau_2\\
CR_i \quad \text{otherwise}
\end{array}
\right.
\end{equation}
where $rndreal[a,b]$ is an uniformly distributed random number between a and b. $\tau_1 =0.1, \tau_2 =0.1$ indicate probabilities to adjust factors $F_i$ and $CR_i$. The newly generated $F_i$ and $CR_i$ are obtained before the mutation and crossover operations. Therefore, they influence the following recombination and selection. The method has been proved efficient based on some benchmark experimental results.\\

Although the above attempts have shown the potential of parameter self-adaptation technique in improving DE performance, the premature convergence during evolution remains a significant and challenging research topic. In the second propose of this paper, we adopt clearing niching method in mutation strategy combined with a two-layer parameter learning DE which intended to improve the efficiency and robustness of the system.

Several enhanced strategies for diversity maintenance have been proposed which target different stages of the evolution process. Niching method is on of the well known strategies proposed to reduce the effects of evolution drift resulting from the selection mechanism, to allow the formation and the maintenance of different solutions and to prevent the DE from being trapped in local optima.

In the niching method the analogy with nature is straightforward. As in an ecosystem there are different subsystems that contain many diverse species\cite{de1975analysis}. The number of elements in a niche is determined by its resources and by the efficiency of each individual in taking profit of these resources. Using this analogy, it is possible for DE to maintain its population diversity during the evolution.

Inspired by former relative works on balance searching and keep diversity during evolution, we propose follow two method to enhance DE mainly from keeping diversity and balance searching.


\chapter{Adaptive Niching DE with Boltzmann Scheme}


\section{Niching Boltzmann DE}

\subsection{Niching mutation strategy}

The Niching Boltzmann DE mainly has the same procedures as conventional DE, initialization, mutation, crossover and selection. Blotzmann framework in which the probability of selecting an individual to become a parent is proportional to its fitness value and inversely proportional to its searching history. By favoring search in the vicinity of the mutated individual this framework promotes efficient balance between exploration and exploitation, without substantially diminishing the exploration of the mutation operator. The proposed framework can be described in follow figure(\ref{NBde}). 

\begin{figure}[ht]
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=8cm]{NBde.jpg}\\
  \caption{The evolution procedure of Niching Boltzmann DE}\label{NBde}
\end{figure}


The procedures of proposed DE is as follows:

$1)Initialization$

Randomly initializing a population of $NP$, $D$-dimensional vectors $X_i^g$,$i=1,2,\dots,NP$, which represent the candidate solutions and aim to achieve the global optimization of domain during evolution. We denote generations $g\in \{0,1,\dots G\}$ in DE and the $i^{th}$ vector of the population at the current generation as%
\begin{equation}
X_i^g=[X_{i,2}^g,X_{i,2}^g,\dots X_{i,D}^g]
\end{equation}
where $i\in [1,N]$. The initialization step is the same with conventional DE.\\


$2) \:Niche-Boltzmann\: scheme$

Before mutation strategy, we use Niching-Boltzmann to choose potential individuals from current population, as the target vector $X_{N_i}^g$. As shown in Fig.\ref{NBde}, Ranking the fitness value of $X_i^g$ in order, and calculating the distance matrix between each individual. Choose the best individual as the core and ``draw'' the first circle with radius $\sigma$, then choose the first $k$ individuals in that niche and clear others as 0. This procedure continues till all the individuals are selected in $X_k$ or cleared to 0.

Shown in Fig\ref{clear}, the black ones are best individuals, use radius $\sigma$ to cluster its domain in fitness order, then Boltzmann scheme decides the capacity $k$ in each niche, representing in gray dots. The removed individuals are also cleared individuals, which are reset to zero after niches are decided. For different niche, we choose different $k(n_i)$ individuals for target vectors in mutation strategy, and the Boltzmann scheme is proposed to decide the number of $k(n_i)$ in the niche $n_i$, which we will describe in detail at the next sub section.\\

\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=9cm]{clear.jpg}
  \caption{Niches clustered by clearing procedure}\label{clear}
\end{figure}

A static radius $\sigma$ is used to partition the niches in a conventional niching clearing method. Then, the $k$ best individuals are selected from each niche respectively and a combination of selected individuals is applied to estimate probabilistic model of DE.

$3) \:Mutation$

For each target vector $X_i^g$, a mutation vector $V_i^g$ is generated by the basic "rand/1/bin" strategy:

\begin{equation}
V_i^g=X_{N_r}^g+F(X_{r_1}^g-X_{r_2}^g),\: r_1\neq r_2\neq i
\end{equation}
where $N_r$ is randomly chosen from former referred set of niching capacity $X_k$. Individuals of step vector $(X_{r_1}^g-X_{r_2}^g)$ are randomly chosen from original population $NP$, which keeps the various of evolution steps. \\

%=============================================================================
$3) \:Crossover$

The crossover procedure is also the same with conventional DE, which determined as:
\begin{equation}
U_{i,j}^g=\left\{%
\begin{array}{ll}V_{i,j}^g \quad \text{if}\:rand_{i,j} (0,1)\leq CR_{i,j} \:or \: j=j_{rand}\\
X_{i,j}^g \quad \text{otherwise}.
\end{array}
\right.
\end{equation}
$j=1,2,\dots,D$ and $rand_{i,j}$ is the $j^th$ evaluation of a uniform random number generator with outcome $\in[0,1]$.\\

%=============================================================================

$4)\: Selection$

By completing to the fitness values, selection operation determines whether the target vector or the trail vector survives to the next generation. Choosing the survive one between target vector $X_i^g$ and trail vector $U_i^g$, greedy criterion is used as follow equation%
\begin{equation}
X_i^{g+1}=\left\{%
\begin{array}{ll}U_i^g \quad if \: f(U_i^g)<f(X_i^G)\\
X_i^g \quad otherwise.
\end{array}
\label{eq4}
\right.
\end{equation}
where $f(X_i)$ is the function to be minimized. Keep the population size as constant over subsequent generation, the object function value of trail vector $f(U_i^g)$ is compared to the corresponding value of target vector $f(X_i^g)$. If the trail vector $U_i^g$ has an equal or lower object function than that of its target vector $X_i^g$, it replaces the target corresponding target vector and survives in the next generation; otherwise, the target vector remain its place in the population.\\


\subsection{Balance searching}
An efficient DE with a balance searching should have the behaviors described as follows. The degree of exploration is monotonically decreasing, while the degree of exploitation is monotonically increasing during the search run. To realize this efficient searching procedure with a balance between exploration and exploitation, which means at the beginning of evolution, the searching area should be as large as possible, and after several iterations, the evolution will be better to converge into interesting areas instead of poor performance areas. The capacity $k$ should be large at first and then gradually reduced.


The capacity parameter $k$ is defined as the maximum number of winners a certain niche can accept. In the conventional method ,the capacity $k$ is set as a static value for all niches, and it can be set in arange from 1 to the population size, which is convenient for maximized or minimized effect.

A balanced niching searching strategy based on DE is introduced. 1) The values of the clearing radius $\sigma$ are determined by distance matrix of individuals calculated in every generation, the individuals are clustered before submitting them to the niching clearing and a cluster can be seen as a niche. 2) A niche capacity $k$ selection mechanism based on the Boltzmann scheme is utilized to realize a balance searching. For a certain niche, the number of winners represents the searching power of DE in this searching area. Therefore, the niche capacity selection can be utilized to tune the searching behavior of DE.


During the evolution, a set of selected individuals are used to estimate the probabilistic model. Set M as the selected population size in each generation, and in order to realize a balance searching procedure, a mechanism of niche capacity selection based on Boltzmann scheme is defined as following equations:

\begin{equation}
k_g(n_i)=M\times[w_g\times E_{i_g}(n_i)+(1-w_g)\times E_{r_g}(n_i)]
\end{equation}
where $n_i$ is the $i$-th niche of $g$-th generation, $w_t$ is a Boltzmann weight of $t$-th iteration, which can be described as follows:

\begin{equation}
w_g=[\frac{e^{\frac{g}{FES_{max}}}-1}{e-1}]^\alpha, 1<i<cl_g
\end{equation}
where $FES_{max}$ is the maximum iterations of the algorithm. And the scaling factor $\alpha$ is a parameter to tune the Boltzmann scheme.

In the proposed mechanism of niche capacity selection, two different selection strategies are assembled by the Boltzmann weight $w_g$ related with teh generation $g$. Tuned by this weight, the searching procedure explores the search areas as more as possible by dominating the exploration strategy, at the end of searching, the searching exploitation is enforced to refine the already found solutions by dominating the exploitation strategy.

\subsection{The Exploitation probability $E_{r_g}(n_i)$}

During the searching procedure for optimal values, if a certain area has searched before and shown poor performance, then we do not want to search it again which wastes time, so a punishment mechanism is needed. A niche novelty metric is proposed to record the overlapping information, and it is used to evaluate the degree of the corresponding niche explored by the previous searching. The niches with smaller novelty metric values will be punished moderately at the exploration searching strategy to realize the diversity preservation at the niche level.

The niche novelty metric $nov_g(n_i)$ of niche $n_i$ in the $g$-th generation is defined as follows.
\begin{equation}
nov_g(n_i)=\beta ^{O_g(n_i)}, \quad 0<\beta<1
\end{equation}
where $n_i$ denotes the $i$-th niche, $\beta$ is the penalty parameter for niche novelty, and $O_g(n_i)$ the overlapping parameter of niche $n_i$ in the $g$-th generation.

Describe a niche $n_i$ at generation $g$ by the center $C_g(n_i)$ and radius $\sigma_g(n_i)$ where the center determining its position and the radius determining the area locating. If the center of a niche $n_i$ in the $g$-th generation is inside the niche $n_j$ of $g-1$ generation, that means, the distance between two centers $C_{g-1}(n_j)$ and $C_g(n_i)$ is less than the radius $\sigma_{g-1}(n_j)$, in this case, this niche $n_i$ is overlapped by $n_j$ of $g-1$ generation.

Set $O_g(n_i)=0$ as the initial value. If the niche $n_i$ is one of the $k$ niches that are overlapped by the niche $n_j$ from former generation, then set overlap value with:

\begin{equation}
O_g(n_i)=O_{g-1}(n_j)+1
\end{equation}

Equation upon is with probability $\frac{k-1}{k}$, which means, among all the $k$ niches, only one keeps to 0, and other $k-1$ niches are set to $O_{g-1}(n_j)+1$ .


The niche novelty metric reflects the information of search space explored by the DE, and the exploration searching probability $E_{r_g}(n_i)$ is defined by a novelty-proportionate strategy as follows:

\begin{equation}
E_{r_g}(n_i)=\frac{nov_g(n_i)}{\sum\limits_{j=1}^{cl_g}nov_g(n_j)}
\end{equation}
where $cl_g$ is the cluster number of the $g$-th iteration population.




\subsection{The Exploitation probability $E_{i_g}(n_i)$}

A popular fitness-proportionate method is used as exploitation strategy of niching DE, the exploitation searching probability $E_{i_g}(n_i)$ is calculated by:
\begin{equation}
E_{i_g}(n_i)=\frac{f_g(n_i)}{\sum\limits_{j=1}^{cl_g}f_g(n_j)}
\end{equation}
where $f_g(n_i)$ is the maximum fitness value of the $i$-th niche in the $g$-th iteration.\\

The fitness-proportionate niche capacity selection is defined based on the best fitness value in a niche. It can guide the DE to search more promising area than uninteresting area.

For better understanding, the framework of the first proposed clearing niching with Boltzmann scheme is described as follows:

1. Generate the first population of NP individuals in stochastic, the individuals should be initialize to cover different areas in the search space, which NP should be not too small, we set NP to 100.

2. Evaluate each individuals of the current population, then the individuals of current population is grouped into clusters by clearing niching method based on a certain distance metric.

3. Calculate the novelty metric for each cluster and evaluate each niche by its best solution found.

4. Estimate the probabilistic model from the selected individuals, save the winner set as the pool for target vectors.

5. Randomly choosing target vectors from capacity $k$, and step vectors $x_{r_2}-x_{r_3}$ are randomly choose from the original population NP.

6. Crossover and selection procedures are exactly the same with conventional DE, by using greedy strategy, a new population for the next iteration is generated.

\section{Simulations on Niching Boltzmann DE}

\subsection{Results Quality}

The main object is to enhance DE to a more stable and efficient evolution algorithm, so the average optimal value, success rate, converge curves are some typical measurement of evaluate our proposed method. Since each time, the population NP is randomly chosen from the domain, so it is necessary to calculate the results for multiple times, for a matter of fairness, all the results of tables in this paper are calculated more than 50 times. Average optimal minimization result value and successful rate are shown in Table\ref{result1}.

From Table\ref{result1} we can observe that, our proposed method mostly as good as conventional DE, and has some improvement in results, especially unimodal function$f_4$, multimodal function $f_8$, and shifted and rotated function $f_{18}-f_{20}$. However, it's unfortunately that some of the functions came out with bad results, such as $f_3$.

The success rate is also shown in Table \ref{result1}, a success is counted when the optimal value this algorithm get reaches the range within acceptable error. By comparing the success rate in running over 50 times, despite some specific functions $f_3$ and $f_{17}$, that the success rate decreased. In most cases, the success rate raises. To be mention that, for function $f_4$, $f_7$ and $f_{14}$, our proposed method make it possible to calculate the result beyond acceptable value.
\begin{table}[ht]
\renewcommand{\arraystretch}{0.7}
\caption{Comparison of results and success rate}
\label{outcome}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{}
&\multicolumn{2}{c|}{conventional DE}
&\multicolumn{2}{c|}{niching Boltzmann DE}\\
\hline
\multicolumn{1}{|c|}{Function}
&\multicolumn{1}{c|}{result}
&\multicolumn{1}{c|}{success}
&\multicolumn{1}{c|}{result}
&\multicolumn{1}{c|}{success}     \\
\hline
$f1$	&	2.84E-111	&	100.00\%	&	3.69E-130	&	100.00\%	\\	\hline
$f2$	&	2.42E-71	&	100.00\%	&	1.22E-72	&	100.00\%	\\	\hline
$f3$	&	5.71E-08	&	100.00\%	&	0.259	&	0.00\%	\\	\hline
$f4$	&	16.94	&	0.00\%	&	7.25E-07	&	100.00\%	\\	\hline
$f5$	&	3.08E-33	&	100.00\%	&	7.33E-16	&	100.00\%	\\	\hline
$f6$	&	0.0023	&	0.00\%	&	0.0018	&	0.00\%	\\	\hline
$f7$	&	18.89	&	0.00\%	&	13.31	&	10.00\%	\\	\hline
$f8$	&	2686.6	&	0.00\%	&	718.6	&	0.00\%	\\	\hline
$f9$	&	1.78E-15	&	100.00\%	&	1.78E-15	&	100.00\%	\\	\hline
$f10$	&	3.55E-15	&	100.00\%	&	3.55E-15	&	100.00\%	\\	\hline
$f11$	&	1.11E-16	&	100.00\%	&	1.11E-16	&	100.00\%	\\	\hline
$f12$	&	1.57E-32	&	100.00\%	&	2.22E-17	&	100.00\%	\\	\hline
$f13$	&	1.35E-32	&	100.00\%	&	1.89E-16	&	100.00\%	\\	\hline
$f14$	&	35.95	&	0.00\%	&	21.35	&	5.00\%	\\	\hline
$f15$	&	0.0099	&	15.00\%	&	0.00026	&	30.00\%	\\	\hline
$f16$	&	20.89	&	0.00\%	&	20.84	&	0.00\%	\\	\hline
$f17$	&	1.77E-15	&	100.00\%	&	1.85E-06	&	30.00\%	\\	\hline
$f18$	&	113.14	&	0.00\%	&	43.23	&	0.00\%	\\	\hline
$f19$	&	33.33	&	0.00\%	&	10.982	&	0.00\%	\\	\hline
$f20$	&	43831.8	&	0.00\%	&	4741.6	&	0.00\%	\\	\hline

\end{tabular}
\end{center}
\label{result1}
\end{table}




\subsection{Converge Curves}

Since niching method has its property to speed up the convergence, the converge curves should show a rapid decrease in finding optimal values. As shown in Fig.\ref{conv4}, these are converge curves from different types of functions, unimodal, multimodal, shifted and rotated complex functions. It's worth mention that, the proposed method and conventional DE evolute with the same population randomly generated from the same domain. Also, the results of converge are shown in title of each figure.

Fig.\ref{conv4} represents that, within the results of all these functions, our proposed method has better performance. For the sub-figure (a)(b)(d), the niching Boltzmann DE show fast convergence speed than conventional DE, and converge generations are less than half of the iterations from DE. But some functions show slow convergence shown in sub-figure (c), where the proposed method use more iterations to get a better optimal.

Therefore, we can know that, the convergence of the evolution varies from different functions, which is exactly Boltzmann scheme used to self-adjust searching procedure. When the optimal value is hard to search, and no previous data, this scheme keep the evolution in exploration instead of quickly converge. When the searching area is promising and interesting, Boltzmann scheme keep the evolution around this certain area and hope to find a better optimal value.

\begin{figure}[htbp]
\centering
\subfigure[$Schwefel's 2.1$]{
\centering
{\includegraphics[width=7.5cm,height=6cm]{conv4.jpg}}
 }
\hspace{0.1cm}
\subfigure[$Generalized Penalized$]{
\centering
{\includegraphics[width=7.5cm,height=6cm]{conv13.jpg}}
 }
\vspace{1cm}
\subfigure[$Shifted Rotated Weierstrass$]{
\centering
{\includegraphics[width=7.5cm,height=6cm]{conv19.jpg}}
 }
\hspace{0.1cm}
 \subfigure[$Schwefel's 2.13$]{
\centering
{\includegraphics[width=7.5cm,height=6cm]{conv20.jpg}}
 }
\caption{ The converge curves of functions}
\label{conv4}
\end{figure}

Moreover, the Boltzmann scheme keep the step vector from large to small, at first the exploration searching is as broad as possible, which needs large step vectors. As iteration goes on, the step vector will also converge to a little tiny steps for a detail search. A symbolic converge of step vectors from $Schwefel's \:Problem\: f_{20}$, which is shown in Fig.\ref{step}. The average value of step vector $X_{r_2}^g-X_{r_3}^g$ from conventional DE is colored in blue, which represents its range laying between 2 and 3 from the beginning of the iteration and barely changed. While the average value of step vector $X_{r_2}^g-X_{r_3}^g$ from niching Boltzmann DE which colored in red, represents its range various ideally: at first, take big steps to search as big area as possible, then converge the steps to smaller ones and find optimal values of interesting areas in detail.

\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=9cm]{x2x3.jpg}\\
  \caption{converge of step vectors}
  \label{step}
\end{figure}



\subsection{Population Sensitivity}

As we know that DE is very sensitive to the setting of control parameters, the niching Boltzmann DE change the pattern of mutation strategy but remain other steps such as initialization, crossover, selection. One of the most important control parameters is population size $NP$, which is determined in initialization step. For conventional DE, the sensitivity of population is tested by Table\ref{popDE}, which confirm that the control parameters influence the results, and different functions need different parameters.


\begin{table*}[ht]
\renewcommand{\arraystretch}{0.6}
\caption{Population Sensitivity of Conventional DE by experiment}
\label{outcome}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}

\hline
\multicolumn{1}{|c|}{Function}
&\multicolumn{1}{c|}{POP:30}
&\multicolumn{1}{c|}{POP:50}
&\multicolumn{1}{c|}{POP:100}
&\multicolumn{1}{c|}{POP:300}
&\multicolumn{1}{c|}{POP:1000}     \\
\hline
$f1$	&	1.20E-38	&	1.20E-38	&	1.29E-38	&	6.25E-20	&	0.0057	\\	\hline
$f2$	&	1.12E-38	&	1.00E-38	&	1.06E-38	&	1.94E-12	&	0.0065	\\	\hline
$f3$	&	0.13	&	0.0012	&	5.71E-08	&	0.051	&	8.68	\\	\hline
$f4$	&	1.21E-10	&	0.013	&	6.94	&	1733.42	&	21687.74	\\	\hline
$f5$	&	3.08E-33	&	3.08E-33	&	3.08E-33	&	7.83E-24	&	0.0023	\\	\hline
$f6$	&	0.00098	&	0.00095	&	0.00236	&	0.00769	&	0.0396	\\	\hline
$f7$	&	21.51	&	4.95	&	14.89	&	21.15	&	33.49	\\	\hline
$f8$	&	2741.46	&	845.7	&	2628.6	&	2066.33	&	2125.22	\\	\hline
$f9$	&	5.97	&	1.78E-15	&	1.78E-15	&	2.08E-08	&	13.77	\\	\hline
$f10$	&	3.55E-15	&	3.55E-15	&	3.55E-15	&	3.58E-11	&	0.0071	\\	\hline
$f11$	&	2.22E-16	&	1.11E-16	&	1.11E-16	&	1.11E-16	&	0.017	\\	\hline
$f12$	&	1.57E-32	&	1.57E-32	&	1.50E-32	&	2.99E-22	&	6.49E-05	\\	\hline
$f13$	&	1.35E-32	&	1.35E-32	&	1.35E-32	&	1.14E-20	&	0.0011	\\	\hline
$f14$	&	17.57	&	12.64	&	13.73	&	24.73	&	637.85	\\	\hline
$f15$	&	0.025	&	0.0074	&	0.0099	&	0.0097	&	1.379	\\	\hline
$f16$	&	20.79	&	20.89	&	20.99	&	21.02	&	20.96	\\	\hline
$f17$	&	10.95	&	1.99	&	1.77E-15	&	1.19E-10	&	14.14	\\	\hline
$f18$	&	56.13	&	82.22	&	60.51	&	119.56	&	220.79	\\	\hline
$f19$	&	30.44	&	31.73	&	33.22	&	31.15	&	35.28	\\	\hline
$f20$	&	5820.31	&	13895.37	&	43831.75	&	63278.12	&	111698.46	\\	\hline

\end{tabular}
\end{center}
\footnotesize Average over 50 independent runs, with 20 benchmark functions in total, this table shows average best results of conventional DE calculate in 5000 iterations.
\label{popDE}
\end{table*}

Under the same condition, we give a experiment in our proposed niching Boltzmann DE, the results of all benchmark functions in population from 30 to 1000 is shown in Table\ref{popnb}. By observing this table we can know that, differences between different population size are not as big as conventional DE, but mainly reflects that bigger population size leading to better performance. For example, $f_3$, $f_9$, $f_{17}$ show great improvement when changing the population size from 30 to 1000, which means the niching method needs more individual to choose, and the population size should be big enough(over 100).
\begin{table*}[ht]
\renewcommand{\arraystretch}{0.6}
\caption{Population Sensitivity of Niching Boltzmann DE by experiment}
\label{outcome}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}

\hline
\multicolumn{1}{|c|}{Function}
&\multicolumn{1}{c|}{POP:30}
&\multicolumn{1}{c|}{POP:50}
&\multicolumn{1}{c}{POP:100}
&\multicolumn{1}{|c|}{POP:300}
&\multicolumn{1}{c|}{POP:1000}     \\
\hline
$f1$	&	1.11E-38	&	1.18E-38	&	1.01E-38	&	1.09E-38	&	1.35E-38	\\	\hline
$f2$	&	1E-38	&	1.06E-38	&	1.17E-38	&	1.03E-38	&	1E-38	\\	\hline
$f3$	&	5.55	&	4.93	&	0.25926	&	0.102	&	0.112	\\	\hline
$f4$	&	0.0057	&	0.0000457	&	0.000000479	&	0.00000121	&	3.6649E-07	\\	\hline
$f5$	&	6.03E-15	&	7.21E-16	&	7.33E-16	&	5.64E-16	&	4.7E-16	\\	\hline
$f6$	&	0.0018	&	0.0039	&	0.00204	&	0.0023	&	0.0025	\\	\hline
$f7$	&	23.65	&	18.73	&	14.31	&	15.76	&	15.39	\\	\hline
$f8$	&	517.1	&	643.4	&	718.6	&	956.04	&	777.88	\\	\hline
$f9$	&	12.93	&	1.99	&	1.78E-15	&	1.77E-15	&	3.55E-15	\\	\hline
$f10$	&	1.42E-14	&	3.55E-15	&	3.55E-15	&	3.55E-15	&	3.55E-15	\\	\hline
$f11$	&	1.11E-16	&	1.11E-16	&	1.11E-16	&	1.11E-16	&	1.11E-16	\\	\hline
$f12$	&	7.69E-17	&	1.43E-17	&	1.08E-17	&	1.18E-17	&	2.39E-17	\\	\hline
$f13$	&	9.49E-16	&	2.73E-16	&	3.8E-16	&	1.56E-16	&	2.88E-16	\\	\hline
$f14$	&	9.95	&	3.55	&	17.76	&	16.81	&	13.97	\\	\hline
$f15$	&	0.015	&	0.0000127	&	2.41E-09	&	1.94E-09	&	0.00986	\\	\hline
$f16$	&	20.77	&	20.82	&	20.91	&	20.97	&	20.97	\\	\hline
$f17$	&	12.93	&	4.97	&	1.85E-12	&	4.51E-12	&	4.76E-12	\\	\hline
$f18$	&	92.53	&	53.72	&	52.73	&	52.73	&	49.75	\\	\hline
$f19$	&	19.01	&	17.46	&	10.84	&	10.01	&	14.13	\\	\hline
$f20$	&	2013.77	&	3915.04	&	4741.55	&	2663.6	&	2011.09	\\	\hline

\end{tabular}
\end{center}
\footnotesize Average over 50 independent runs, with 20 benchmark functions in total, this table shows average best results of JADE calculate in 5000 iterations.
\label{popnb}
\end{table*}

For a better comparison, we put the conventional DE and niching Boltzman DE together for a clearer instruction. With the same fixed control parameters $F=CR=0.5$. The ones with big difference from different population size, we mark them as bold face to easily be recognized. Table\ref{DEvsnb} tells the improvement of our proposed method, which is much more stable.

\begin{table*}[ht]
\renewcommand{\arraystretch}{0.6}
\caption{Compare of population sensitivity}
\label{outcome}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}

\hline
\multicolumn{1}{|c|}{Compare}
&\multicolumn{2}{c|}{conventional DE}
&\multicolumn{2}{c|}{niching Boltzmann DE}\\
\hline
\multicolumn{1}{|c|}{Function}
&\multicolumn{1}{c|}{POP:100}
&\multicolumn{1}{c|}{POP:300}
&\multicolumn{1}{c|}{POP:100}
&\multicolumn{1}{c|}{POP:300}    \\
\hline
$f1$	&	1.29E-38	&	6.25E-20	&	1.01E-38	&	1.09E-38	\\	\hline
$f2$	&	1.06E-38	&	1.94E-12	&	1.17E-38	&	1.03E-38	\\	\hline
$f3$	&	5.71E-08	&	\textbf{0.051}	&	0.25926	&	0.102	\\	\hline
$f4$	&	6.94	&	\textbf{1733.42}	&	4.79E-07	&	1.21E-06	\\	\hline
$f5$	&	3.08E-33	&	7.83E-24	&	7.33E-16	&	5.64E-16	\\	\hline
$f6$	&	0.00236	&	0.00769	&	0.00204	&	0.0023	\\	\hline
$f7$	&	14.89	&	21.15	&	14.31	&	15.76	\\	\hline
$f8$	&	2628.6	&	2066.33	&	718.6	&	\textbf{956.04}	\\	\hline
$f9$	&	1.78E-15	&	2.08E-08	&	1.78E-15	&	1.77E-15	\\	\hline
$f10$	&	3.55E-15	&	3.58E-11	&	3.55E-15	&	3.55E-15	\\	\hline
$f11$	&	1.11E-16	&	1.11E-16	&	1.11E-16	&	1.11E-16	\\	\hline
$f12$	&	1.50E-32	&	2.99E-22	&	1.08E-17	&	1.18E-17	\\	\hline
$f13$	&	1.35E-32	&	1.14E-20	&	3.80E-16	&	1.56E-16	\\	\hline
$f14$	&	13.73	&	24.73	&	17.76	&	16.81	\\	\hline
$f15$	&	0.0099	&	0.0097	&	2.41E-09	&	1.94E-09	\\	\hline
$f16$	&	20.99	&	21.02	&	20.91	&	20.97	\\	\hline
$f17$	&	1.77E-15	&	1.19E-10	&	1.85E-12	&	4.51E-12	\\	\hline
$f18$	&	60.51	&	\textbf{119.56}	&	52.73	&	52.73	\\	\hline
$f19$	&	33.22	&	31.15	&	10.84	&	10.01	\\	\hline
$f20$	&	43831.75	&	\textbf{63278.12}	&	4741.55	&	2663.6	\\	\hline

\end{tabular}
\end{center}
\label{DEvsnb}
\end{table*}

By drawing the standard deviation curves in different population, we can make a conclusion that, our proposed method below is less sensitive to the population. In Fig.\ref{5} and Fig.\ref{6} the vertical axis shows the logarithmic value of standard deviation, which means smaller the values are, better results functions get.

Moreover, Fig.\ref{5} shows the performance of DE evolution is not stable when population size varies, for a certain function, it may need time to try out the best population size. On the other hand, our proposed niching Boltzmann DE shows a relatively stable character in different population size. This can due to maintaining diversity by niching method during evolution.
\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=14cm]{pop1}\\
  \caption{STD of Conventional DE in logarithm}\label{5}
\end{figure}

\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=14cm]{pop2}\\
  \caption{STD of Niche Boltzmann DE in logarithm}\label{6}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Two-layered Self-adapting DE with Clearing mutation strategy}

For the purpose of constructing a more efficient and flexible niching DE for the solution of different types of optimization problems, we employ a self-adaptive parameter control in clearing niching DE. As the clearing procedure affects only target vectors and independent to the parameters F and CR, such combination is a worthy try. By this theory, a complete system is formed with the combination of two-layer learning parameters.

\section{Two layered DE with parameter control}

In order to eliminate the time consuming task in fine-tuning control parameters in DE, and to avoid adding too many parameters, we propose a two-layered DE (TLDE) with self-adaptive control parameters based on the previous performance.

As shown in Fig.\ref{ds2}, the TLDE consists of two layers: a top DE layer and a bottom DE layer. The bottom DE layer is a doubled basic DE for normal evolution procedure, while the top DE layer is a simplified DE for self-adapting control parameters.

\begin{figure}[!h]
\centering
\includegraphics[width=10cm]{ds2.jpg}
\caption{Structure of the two-layered DE} \label{ds2}
\end{figure}

The doubled basic DE is a conventional DE described in Chapter \ref{ch2}, evolving parallel with two sets of control parameters. The evolution is divided into multiple evolution periods called learning periods used by the simplified DE in the top layer for control parameter evolution. Each learning period consists of $L_p$ generations with two set of fixed control parameters from the simplified DE in the top layer.


\subsection{The Evolution of niching DE}

As we mentioned dominate individuals (target vectors $X_{r_1}^g$), are highly relevant with convergence efficiency. The target vector in each iteration of searching should cover various niches and represent different niches.

By finding the efficient individuals of niches in each generation, we intended to speed up the convergence. Although we narrow down the domain of target individuals and in each iteration generate as $X_{cr}^g$, the step vector $X_{r_2}^g-X_{r_3}^g$ are still randomly chosen from population $\{X_i^g\}$ to maintain the variety of searching steps. This clearing procedure has no relationship with following mutation, crossover and selection procedures, it can be parallel executed with TLDE.

Pseudo code of clearing procedure is shown in Algorithm \ref{algorithm1}. At the beginning of the $g^{th}$ iteration, rank the fitness value of population in order, draw a circle $C_1^g$ with center at the best fitness individual $X_1^g$ and radius equal to $\delta$ (``Hamming'' distance in simulation). The circle $C_1^g$ may contain other individuals, but only remain the best individual as ``the winner'', then ``clear'' (delete) other individuals in this circle. So far we have got a first niche $N_1^g$ with a winner $X_1^g$, the rest individuals are circling exactly the same as the first one. When there are no other individuals except winners, the clearing procedure completes and we get a smaller population group $\{X_c^g\}$.%

\begin{figure}[t]
\centering
\includegraphics[width=8cm]{3}
\caption{Evolution of the basic DE} \label{4}
\end{figure}

Fig.\ref{4} shows the evolution of the basic DE from $X_i^g\to X_i^{g+1}$. The basic DE is a doubled and parallel one, in which each individual is assigned with two set of control parameters described in Fig.\ref{2}. The two sets of control parameters $(\upsilon F_i^g$, $\upsilon CR_i^g)$ and $(oF_i^g,oCR_i^g)$ are fixed in $L_p$ generations of a learning period. After a learning period, the control parameters of each individual are evaluated with a success rate, which indicates whether and which set of the control parameters are suitable for the next learning period.

Searching procedure with both mutation vectors are computed by the mutation scheme ``DE/rand/1/bin'':%
\begin{equation}
\left\{\begin{array}{ll}
oV_i^g = X_{C_r}^g + oF_i^g \cdot (X_{r_1}^g - \hat{X}_{r_2}^{g-1})\\
\upsilon V_i^g = X_{C_r}^g + \upsilon F_i^g \cdot (X_{r_1}^g - \hat{X}_{r_2}^{g-1})
\end{array}
\right.
\label{eq:eq3}
\end{equation}
where the index $c_r$,$r_1$,$r_2$ are integers chosen among $[1,NP]$, $X_{c_r}$ is randomly chosen from winner set $\{X_c^g\}$ after clearing procedure, which we will describe later in detail. $X_{r_1}$is a random vector from current population $\{X_{1,2,\dots,NP}^g\}$,
while $\hat{X}_{r_2}^{g-1}$ is chosen from vectors of backup set from last learning period $\{X_b^g\}$, randomly.

As we have got a pair of trail vectors $oV_i^g$ and $\upsilon V_i^g$, the next step crossover with $oCR_i$ and $\upsilon CR_i$ is described as follows:
\begin{equation}
oU_{i,j}^g=\left\{
\begin{array}{ll}oV_{i,j}^g \quad \text{if} \: rand_{i,j} (0,1)\leq oCR_{i,j}^k\:or\:j=j_{rand}\\
X_{i,j}^g \quad \text{otherwise}.
\end{array}
\label{eq:eq4}
\right.
\end{equation}
\begin{equation}
\upsilon U_{i,j}^g=\left\{
\begin{array}{ll}\upsilon V_{i,j}^g\quad \text{if} \quad rand_{i,j} (0,1)\leq \upsilon CR_{i,j}^k\:or \:j=j_{rand}\\
X_{i,j}^g\quad \text{otherwise}.
\end{array}
\right.
\label{eq:eq5}
\end{equation}

After mutation, crossover procedure in the second layer, those vectors get from equation (\ref{eq:eq4})(\ref{eq:eq5}) supply a richer set to select target vectors:%
\begin{equation}
X_i^{g+1}=\left\{
\begin{array}{lll}oU_i^g\quad \text{if} \quad f(oU_i^g)\leq Min_i^g\\
\upsilon U_i^g\quad \text{if} \quad f(\upsilon U_i^g)\leq Min_i^g\\
X_i^g\quad \text{otherwise}.
\end{array}
\right.
\label{eq:eq6}
\end{equation}
where $Min_i^g$ defines as $\min\{f(oU_i^g),f(\upsilon U_i^g),f(X_i^g)\}$ for we need to find out the global minima. But if the trail vectors $oU_i^g$ or $\upsilon U_i^g$ is not the best one but better than $X_i^g$, it will be reserved to backup solution set $\{X_b^g\}$ and participate mutation in next generation by equation (\ref{eq:eq3}).

As we mentioned dominate individuals (target vectors $X_{r_1}^g$), are highly relevant with convergence efficiency. The target vector in each iteration of searching should cover various niches and represent different niches.

Pseudo code of clearing procedure is shown in Algorithm \ref{algorithm1}. At the beginning of the $g^{th}$ iteration, rank the fitness value of population in order, draw a circle $C_1^g$ with center at the best fitness individual $X_1^g$ and radius equal to $\delta$ (``Hamming'' distance in simulation). The circle $C_1^g$ may contain other individuals, but only remain the best individual as ``the winner'', then ``clear'' (delete) other individuals in this circle. So far we have got a first niche $N_1^g$ with a winner $X_1^g$, the rest individuals are circling exactly the same as the first one. When there are no other individuals except winners, the clearing procedure completes and we get a smaller population group $\{X_c^g\}$.

By finding the efficient individuals of niches in each generation, we intended to speed up the convergence. Although we narrow down the domain of target individuals and in each iteration generate as $X_{cr}^g$, the step vector $X_{r_2}^g-X_{r_3}^g$ are still randomly chosen from population $\{X_i^g\}$ to maintain the variety of searching steps. This clearing procedure has no relationship with following mutation, crossover and selection procedures, it can be parallel executed with TLDE.

%=============================================================================
\begin{algorithm}
 \renewcommand{\arraystretch}{0.6}
\caption{Evolution of double basic DE}
\begin{algorithmic}[1]
\Require set of winners $\{X_C^g\}$, population $\{X_{NP}^g\}$
\Ensure global minima $f(X_{best})$
    \For {$i=1 \to NP$}\\
  /*generate a pair parameters */
    \State $\upsilon F_i^g\gets oF_i^g+rand_i\cdot (F_{r_1}^g-F_{r_2}^g)$, $\upsilon CR_i^g\gets oCR_i^g+rand_i\cdot (CR_{r_1}^g-CR_{r_2}^g)$\\
  /*generate a pair mutation vectors*/
    \State $oV_i^G \gets X_{Cr}^g + oF_i^g \cdot (X_{r_1}^g - \hat{X}_{r_2}^{g-1})$, $\upsilon V_i^g \gets X_{Cr}^g + \upsilon F_i^g \cdot (X_{r_1}^g - \hat{X}_{r_2}^{g-1})$\\
  /*where clearing winners $X_{Cr}^g \in \{X_C^g\}$\\
  population individuals $X_{r_1}^g \in \{X_{NP}^g\}$\\
  backup individuals $\hat{X}_{r_2}^{g-1} \in \{\hat{X}_B^g\}$ */
 %%==============================================================================
 \For {$j= 1\to D$}
  /*crossover mutation vectors with trail vectors*/
 \If {$j=j_{rand}$ or $rand(0,1)<CR_i$}
 \State $oU_{i,j}^g \gets oV_{i,j}^g$, $\upsilon U_{i,j}^g \gets \upsilon V_{i,j}^g$
 \Else
 \State $oU_{i,j}^g \gets X_{i,j}^g$
 \EndIf
 \EndFor
 \If {$f(oU_i^g)$ is the smallest}
    \State $X_i^{g+1} \gets oU_i^g $, $\{\hat{X}_B^g\} \gets \upsilon U_i^g $
        \ElsIf{$f(\upsilon U_i^g)$ is the smallest}
    \State $X_i^{g+1} \gets \upsilon U_i^g $, $\{\hat{X}_B^g\} \gets oU_i^g $
        \Else
    \State $X_i^{g+1} \gets X_i^g $
        \EndIf
 \EndFor
 %%==============================================================================
 \end{algorithmic}
\label{algorithm2}
\end{algorithm}
%=============================================================================



\subsection{The Evolution of control parameters}

As shown in Fig.\ref{3}, the simplified DE is a conventional DE without crossover operation, for control parameter adaptation. The control parameters are evaluated over the learning period by the basic DE in the bottom layer.\\


\begin{figure}[!h]
\centering
\includegraphics[width=6cm]{4.jpg}
\caption{Evolution of the simplified DE for control parameter adaptation} \label{3}
\end{figure}

%=============================================================================
1) \emph{Initialization}

In order to realize a self-adaptation of control parameters by DE, we create a population of control parameters by assigning a set of control parameters to each individual of the basic DE in the bottom layer, which are randomly initialized. As shown in Fig.\ref{1}, $X_i^g$ denotes the $i$ individual in the $g$th generation, while $F_i^g$ and $CR_i^g$ the corresponding control parameters.\\
%
\begin{figure}[H]
\centering
\includegraphics[width=9cm]{1.jpg}
\caption{Individuals and the corresponding control parameters} \label{1}
\end{figure}

2) \emph{Mutation}

The mutation is performed for generating new control parameters.
\begin{equation}
\left\{\begin{array}{l}
\upsilon F_i^g=oF_i^g+\omega _i\cdot (F_{r1}^g-F_{r2}^g),\\
\upsilon CR_i^g=oCR_i^g+\omega _i\cdot (CR_{r1}^g-CR_{r2}^g).
\end{array} \right.
\label{eq:eq1}
\end{equation}
where $(oF_i^g,oCR_i^g)$ are control parameters update from last learning period. $r_1$, $r_2$ $(r_1 \ne r_2)$ and $\omega_i$ are random values uniformly distributed in a range of (0,1).

By this step, we have got two sets of control parameters $[oF_i^g,oCR_i^g]$ and $[\upsilon F_i^g,\upsilon CR_i^g]$ assigned to each individual, see Fig.\ref{2}. These two sets of control parameters are used by the basic DE during a learning period, and which set to be chosen for the next learning period depends on their performance.\\

\begin{figure}[H]
\centering
\includegraphics[width=11cm]{2}
\caption{Two sets of control parameters generated by mutation} \label{2}
\end{figure}

3) \emph{Selection}

It is a natural assumption that better control parameters are more likely to generate better offspring to survive, which inverse, good individuals are more likely generated by individuals with good parameters from last iteration.

However, because of the stochastic characteristics of DE it is hard to evaluate a better control parameter in just one generation, as done in many existing self-adaptive DE algorithms. To solve this problem, instead of generating new control parameters in each generation, we introduce a so called learning period with $L_p$ generations ($L_p=15$ in the simulation), the control parameters remain fixed till the next learning period, and the one with better rate that evolves minimum outcomes will survive.

Moreover, previous parameter selection procedure apply greedy strategy and remain parameters of best individuals. Somewhat differently, we apply a probability $P$ as success rate to evaluate the parameters. Only when the success rate $P$ is higher than a threshold $\tau$, can the parameters be saved. The reason we omit parameters generate better individuals with success rate under $\tau$ is that, a ``spark'' of good control parameters is unstable and has high probability lead to a local optimal.

According this scheme, we intend to keep both local and global search ability to generate potentially good mutation vectors throughout the evolution process. $oP_i^k$ and $\upsilon P_i^k$ represent the probability of generating $i$th individual as optimal value in the $k$th learning period, which are calculated as follows:
\begin{equation}
\begin{array}{ll}
oP_i^k= \sum_{g=L_p\ast(k-1)}^{L_p\ast k} \{f(oU_i^g)\leq Min_i^g\}/L_p\\
\upsilon P_i^k=\sum_{g=L_p\ast(k-1)}^{ L_p\ast k} \{f(\upsilon U_i^g)\leq Min_i^g\}/L_p
\end{array}
\end{equation}
where $oP_i^k$ is the success evolve rate for $(oF_i^k,oCR_i^k)$, and $\upsilon P_i^k$ is for $(\upsilon F_i^k,\upsilon CR_i^k)$.

By comparing the success evolve rate, the better one with probability higher than $\tau$ ($\tau =0.3$) will be selected to replace $(oF_i^{k+1},oCR_i^{k+1})$. For each individual, the pair of parameters $(oF_i^k,oCR_i^k)$ in the $k^{th}$ learning period updates at the same time, according to following equations:

\begin{equation}
(oF_i^{k+1},oCR_i^{k+1})=\left\{
\begin{array}{lll}
(oF_i^{k},oCR_i^{k})  \quad \text{if} \quad oP_i^k\ge Max_i^k \\
(\upsilon F_i^{k},\upsilon CR_i^{k})  \quad\text{if} \quad \upsilon P_i^k\ge Max_i^k \\
(F_{\tau}^{k},CR_{\tau}^{k}) \quad \quad \text{otherwise}\\
\end{array}
\right.
\end{equation}
$Max_i^k$ defines as $\max\{oP_i^k,\upsilon P_i^k,\tau\}$ to find the parameters with highest probability to generate good individuals. Since a certain success rate of parameters are required to ensure individual quality, those control parameters with success rate less than $\tau$ will be regenerated :
\begin{equation}
\left\{
\begin{array}{ll}
F_{\tau}^k= randc_i(\mu F^k,randn)\\
CR_{\tau}^k= randn_i(\mu CR^k,randn)
\end{array}
\right.
\end{equation}
where $randc_i$ is Cauchy distribution and $randn_i$ is normal distribution. Parameters $\mu F$ and $\mu CR$ represent the location parameter of distribution.
\begin{equation}
\left\{
\begin{array}{ll}
\mu F^k =(1-c)\times \mu F^0+ c\times mean_L(S_F^{k})\\
\mu CR^k = (1-c)\times \mu CR^0+ c\times mean_A(S_{CR}^{k})
\end{array}
\right.
\end{equation}
where parameters $\mu F^0$ and $\mu CR^0$ are initialized location as 0.5. c is a positive constant between 0 and 1, which we set to 0.5. $mean_A()$ is the usual arithmetic mean, $S_{CR}^{k}$ is the set of successful crossover probabilities in current learning period. $S_F^{k}$ is the set collect for the F of success evolved population during the learning period, and $mean_L()$ is the Lehmer mean:
\begin{equation}
mean_LS_F=\frac{\sum_{F\in S_F}F^2}{\sum_{F\in S_F}F}
\end{equation}

In this way the control parameter $(oF_i^{k+1},CR_i^{k+1})$ are self-learning and updating after every learning period by choosing better success rate between $(oF_i^k,oCR_i^k)$ and $(\upsilon F_i^k,\upsilon CR_i^k)$. The $k$th learning period is shown in Algorithm \ref{algorithm2}.
\begin{algorithm}
 \renewcommand{\arraystretch}{0.6}
\caption{Selection of parameters}
\begin{algorithmic}[1]
\Require control parameters$(oF_i^{k},oCR_i^{k})$
% selection set$\{oU_i^g\}$, $\{\upsilon U_i^g\}$, $\{X_i^g\}$
\Ensure parameters for next period $(oF_i^{k+1},oCR_i^{k+1})$\\
 /*select the best and save the backup*/


 success rate $oP_i^k \Leftarrow (oF_i^k,oCR_i^k)$,  $\upsilon P_i^k \Leftarrow [\upsilon F_i^k,\upsilon CR_i^k]$
\For {$i=1 \to NP$}
    \If{$oP_i^k >\upsilon P_i^k> \tau$}
    \State $F_i^{k+1} \gets oF_i^k$
    \State $CR_i^{k+1} \gets oCR_i^k$
    \ElsIf{$\upsilon P_i^k> oP_i^k > \tau $}
    \State $F_i^{k+1} \gets \upsilon F_i^k$
    \State $CR_i^{k+1} \gets \upsilon CR_i^k$
    \Else
    \State $F_i^{k+1} \gets randni(\mu F, rand(0,1))$
    \State $CR_i^{k+1} \gets randni(\mu CR, rand(0,1))$
    \EndIf
 \EndFor\\
 %%==============================================================================
 /*Update backup set $\{\hat{X}_b^g\}$ and $B \leq NP$*/
 \State $\mu F \gets (1-c)\times \mu F+ c\times mean_L(S_F^{k})$
 \State $\mu CR \gets (1-c)\times \mu CR+ c\times mean_A(S_{CR}^{k})$
\end{algorithmic}
\label{algorithm3}
\end{algorithm}

\section{Simulations on Niching Two-layered DE}

Table \ref{DE} testify the performance of DE is sensitive to the choice of control parameters. For all those 20 benchmark functions, the success rate by fixed control parameters varies from different functions.
\begin{table}[ht]
 \renewcommand{\arraystretch}{0.6}
\caption{Experiment Results with DE in fixed F, CR}
\begin{center}\begin{tabular}{|l|c c c c c c|c|}
\hline
\multicolumn{1}{|c|}{}
& \multicolumn{1}{c}{0101}
& \multicolumn{1}{c}{0503}
& \multicolumn{1}{c}{0505}
& \multicolumn{1}{c}{0509}
& \multicolumn{1}{c}{0901}
& \multicolumn{1}{c}{0909}
& \multicolumn{1}{|c|}{TLDE}\\
 \hline
$number\: of \:bests$ & 0& 3 &5 &2 &4 &1 &14\\
$success rate$ &46.0\% &69.5\% &69.8\% &60.0\% &56.7\% &50.3\% &72.3\%\\ \hline
\end{tabular}
\label{DE}
\end{center}
\end{table}

Considering the commonly used parameter settings, we choose $(F,CR)$ as (0.1,0.1), (0.5,0.3), (0.5,0.5), (0.5,0.9), (0.9,0.1) and (0.9,0.9) to investigate the influence of DE parameters. In fairness, we compared to the proposed two-layer structured parameter learning DE without niching procedure, due to the parameters are the only part of adjustment. In this table, we simply show the number of best results and success rate among twenty functions after statistics. For conventional DE, results are not surprisingly vary from different parameters, while TLDE with self-learning parameters shows a significant improvement.


\subsection{Average optimal results}

\begin{table*}[htbp]
\renewcommand{\arraystretch}{0.53}
\caption{experimental results of Niching Two-Layer DE with different parameter control methods for selected benchmark functions}
\label{outcome}
\begin{center}
\begin{tabular}{|ll|c c c|c c|}

\hline
\multicolumn{2}{|c|}{Function}
&\multicolumn{1}{c}{JADE}
&\multicolumn{1}{c}{jDE}
&\multicolumn{1}{c}{SDE}
&\multicolumn{1}{|c}{TLDE}
&\multicolumn{1}{c|}{NTLDE}     \\

\hline
$f1$	&	$mean$	&	9.5747E-176	&	1.12324E-71	&	7.08806E-65	 &	3.43445E-85	&	 1.88516E-97	\\	
	&	$std$	&	0	&	1.56921E-71	&	1.72457E-64	&	 4.45155E-85	&	3.40189E-97	\\	 \hline
$f2$	&	$mean$	&	2.04000E-39	&	2.93095E-41	&	1.53133E-38	 &	\textbf{1.54301E-48}	&	 \textbf{6.86622E-56}	\\	
	&	$std$	&	7.38514E-39	&	1.21711E-41	&	3.57502E-38	&	 1.04599E-48	&	 7.7398E-56	\\	\hline
$f3$	&	$mean$	&	\textbf{6.60117E-70}	&	1.30181E-07	&	 7.37197E-09	&	6.04986E-08	&	 \textbf{2.12986E-17}	\\	
	&	$std$	&	1.3709E-69	&	5.02363E-07	&	1.18436E-08	&	 4.24645E-08	&	 2.99457E-17	\\	\hline
$f4$	&	$mean$	&	\textbf{1.91456E-90}	&	0.001073383	&	 634.1286944	&	1.123664137	&	 \textbf{1.26035E-07}	\\	
	&	$std$	&	6.44987E-90	&	0.001130412	&	460.6213902	&	 0.731622424	&	 1.31483E-07	\\	\hline
$f5$	&	$mean$	&	0	&	0	&	0	&	0	&	0	\\	
	&	$std$	&	0	&	0	&	0	&	0	&	0	\\	\hline
$f6$	&	$mean$	&	\textbf{0.000420116}	&	0.002599212	&	 0.003565094	&	0.007139964	&	 \textbf{0.001872842}	\\	
	&	$std$	&	0.00018554	&	0.000477625	&	0.000680896	&	 0.001708176	&	 0.000518219	\\	\hline
$f7$	&	$mean$	&	0	&	0.019385439	&	6.440664692	&	 4.10142E-06	&	3.82834E-07	 \\	
	&	$std$	&	0	&	0.01445572	&	1.767738152	&	 7.14615E-06	&	4.22734E-07	\\	 \hline
$f8$	&	$mean$	&	7.896270801	&	7.896270801	&	0.000381827	 &	\textbf{0.000381827}	&	 \textbf{0.000381827}	\\	
	&	$std$	&	30.5806465	&	30.5806465	&	3.82746E-12	&	 1.12226E-19	&	0	\\	 \hline
$f9$	&	$mean$	&	0	&	0	&	0.066330604	&	0	&	0	 \\	
	&	$std$	&	0	&	0	&	0.256897324	&	0	&	0	\\	 \hline
$f10$	&	$mean$	&	3.55271E-15	&	3.55271E-15	&	4.02641E-15	 &	5.21065E-15	&	 3.55271E-15	\\	
	&	$std$	&	1.79507E-21	&	4.08274E-31	&	1.25008E-15	&	 1.83461E-15	&	 4.08274E-31	\\	\hline
$f11$	&	$mean$	&	0	&	0	&	0	&	0	&	0	\\	
	&	$std$	&	0	&	0	&	0	&	0	&	0	\\	\hline
$f12$	&	$mean$	&	1.57054E-32	&	1.57054E-32	&	1.57054E-32	 &	1.57054E-32	&	 1.57054E-32	\\	
	&	$std$	&	2.32839E-38	&	2.83297E-48	&	1.23207E-38	&	 2.83297E-48	&	 2.83297E-48	\\	\hline
$f13$	&	$mean$	&	1.34978E-32	&	1.34978E-32	&	1.34978E-32	 &	1.34978E-32	&	 1.34978E-32	\\	
	&	$std$	&	1.85636E-38	&	2.83297E-48	&	9.82291E-39	&	 2.83297E-48	&	 2.83297E-48	\\	\hline
$f14$	&	$mean$	&	17.70968785	&	0.669693725	&	12.24961691	 &	\textbf{0.000280592}	&	 \textbf{0.002311603}	\\	
	&	$std$	&	37.08245913	&	1.414356385	&	16.33148722	&	 0.000525148	&	 0.007928373	\\	\hline
$f15$	&	$mean$	&	0.000821399	&	0.001971457	&	0.000657152	 &	\textbf{0.000657152}	&	 \textbf{1.33227E-16}	\\	
	&	$std$	&	0.003181266	&	0.004081304	&	0.00254514	&	 0.00254514	&3.30945E-16	\\	\hline
$f16$	&	$mean$	&	20.91779262	&	20.91489385	&	20.92738663	 &	20.90652409	&	 20.1196963	\\	
	&	$std$	&	0.057436248	&	0.052519767	&	0.048927811	&	 0.037862517	&	 0.11132629	\\	\hline
$f17$	&	$mean$	&	0	&	0	&	0.132661208	&	0	&	0	 \\	
	&	$std$	&	0	&	0	&	0.35009204	&	0	&	0	\\	 \hline
$f18$	&	$mean$	&	\textbf{22.11378903}	&	 \textbf{35.76486345}	&	139.2023223	&	47.11462041	&	 44.79645601	\\	
	&	$std$	&	5.948578981	&	10.41515826	&	16.89396392	&	 8.516641994	&	 10.93542304	\\	\hline
$f19$	&	$mean$	&	25.07342387	&	\textbf{12.87762592}	&	 33.53525092	&	23.03053569	&	 \textbf{9.688993264}	\\	
	&	$std$	&	1.51756617	&	5.200141785	&	1.476459176	&	 2.013521791	&	 3.972020795	\\	\hline
$f20$	&	$mean$	&	3057.418347	&	2048.220986	&	25636.09032	 &	\textbf{1548.603555}	&	 \textbf{997.1170613}	\\	
	&	$std$	&	2449.695545	&	1781.331182	&	26155.62157	&	 1854.102311	&	 1155.611716	\\	\hline

\end{tabular}
\end{center}
\footnotesize Average over 50 independent runs, with 20 benchmark functions in total, this table shows different results of NTLDE with other methods, while other results of NTLDE are as good as the best results of JADE, jDE, SDE, TLDE.
\end{table*}
In order to confirm the proposed method is extensive comparable, we compare the proposed method with some improved DE algorithms that use adaptive or self-adaptive parameter strategies. Specifically, the JADE algorithm proposed by Zhang in 2009\cite{cit:14}, the jDE algorithm proposed by Brest in 2006\cite{cit:16}, and the SDE algorithm proposed by Salman in 2007\cite{cit:12}. Moreover, we use the same population size(NP) as 100, also the same maximum function evolution(FEs) as $5.0\times 10^5$ for a fair comparison in solution quality.

Table \ref{outcome} shows mean value and standard deviation of benchmark functions calculated by JADE, jDE, SDE, TLDE and NTLDE algorithm. Some results such as $f_1$, $f_5$, $f_9-f_{13}$, $f_{16}$, $f_{17}$ are omitted from the table, which because the results of these functions calculate by algorithms upon are similar to each other. Even there exist difference, our proposed method NTLDE is as good as the best result of other algorithms.

Since the population is randomly generated at the beginning, all twenty benchmark functions runs over 50 times by compared algorithms independently. In this table, we put the best two algorithms with best results in bold font. By observing the results table \ref{outcome} listed, we can find out that although the result of NTLDE is not as precise as JADE algorithm for unimodal functions $f_1-f_6$, but the average outcomes are still within the acceptable range. For multimodal function $f_8$, the proposed method get the best acceptable result. The advantages of proposed method are obvious when calculate $f_{14}-f_{20}$, which are complex shifted and rotated functions. Moreover, it's worth noticed that the two-layer structured DE has better performance when add with clearing procedure, especially in $f_4$, $f_{15}$, $f_{19}$ and $f_{20}$. This better performance shows smaller average outcomes and smaller standard deviation, which confirms that the system is more stable as expected.

\subsection{Success rate}

Besides, it is necessary to compare the success rate of best result in over 50 independent runs. In this case, we keep the results of all twenty benchmark functions. The average success rate of TLDE is higher than jDE and SDE but lower than JADE, while NTLDE shows the best average success rate.

For unimodal functions $f_1-f_6$, it is easy to calculate the acceptable result in 100\% by JADE and NTLDE . For multimodal functions  $f_7-f_{13}$ JADE performs a little bit better than NTLDE, in function $f_7$. When dealing with high dimensional shifted and rotated functions $f_{14}-f_{20}$, the proposed method shows a small improvement. Both TLDE and NTLDE make it possible to calculate the best result, although in a low probability 6.67\%. By compare the average success rate from table \ref{succrate}, clearing niching procedure has been proved effective.
\begin{table}[htbp]
 \renewcommand{\arraystretch}{0.6}
\caption{Acceptable Success Rate count by over 50 independent runs}
\begin{center}\begin{tabular}{|c|c c c | c c|}
\hline
\multicolumn{1}{|c|}{Function}
& \multicolumn{1}{c}{JADE}
& \multicolumn{1}{c}{jDE}
& \multicolumn{1}{c|}{SDE}
& \multicolumn{1}{c}{TLDE}
& \multicolumn{1}{c|}{NTLDE}\\
 \hline
$f1$	&100.00\%	&100.00\%	&100.00\%&	100.00\%	&100.00\%\\
$f2$	&100.00\%	&100.00\%	&100.00\%&	100.00\%	&100.00\%\\
$f3$	&100.00\%	&93.33\%	&100.00\%&	100.00\%	&100.00\%\\
$f4$	&100.00\%	&0.00\%	&0.00\%&	0.00\%	&100.00\%\\
$f5$	&100.00\%	&100.00\%	&100.00\%&	100.00\%	&100.00\%\\
$f6$	&100.00\%	&100.00\%	&100.00\%&	100.00\%	&100.00\%\\
\hline
$f7$	&100.00\%	&0.00\%	&0.00\%	&40.00\%	&86.67\%\\
$f8$	&93.33\%	&93.33\%	&93.33\%	&100.00\%	&100.00\%\\
$f9$	&100.00\%	&100.00\%	&93.33\%	&100.00\%	&100.00\%\\
$f10$	&100.00\%	&100.00\%	&100.00\%&	100.00\%	&100.00\%\\
$f11$	&100.00\%	&100.00\%	&100.00\%&	100.00\%	&100.00\%\\
$f12$	&100.00\%	&100.00\%	&100.00\%&	100.00\%	&100.00\%\\
$f13$	&100.00\%	&100.00\%	&100.00\%&	100.00\%&100.00\%\\
\hline
$f14$	&66.67\%	&6.67\%	&0.00\%	&100.00\%	&93.33\%\\
$f15$	&93.33\%	&100.00\%	&100.00\%&	100.00\%	&100.00\%\\
$f16$	&0.00\%	&0.00\%	&0.00\%	&0.00\%&	0.00\%\\
$f17$	&100.00\%	&100.00\%	&86.67\%	&100.00\%	&100.00\%\\
$f18$	&0.00\%	&0.00\%	&0.00\%	&0.00\%	&0.00\%\\
$f19$	&0.00\%	&0.00\%	&0.00\%	&0.00\%	&0.00\%\\
$f20$	&0.00\%	&0.00\%	&0.00\%	&6.67\%	&6.67\%\\
\hline
$average$	&77.67\%	&64.67\%	&63.67\%	&72.33\%	 &79.33\%\\ \hline
\end{tabular}
\label{succrate}
\end{center}
\footnotesize The $f_{5}$ acceptable error is $0$, while $f_{6}$, $f_{8}$ and $f_{14}-f_{19}$ acceptable error is $10e^{-2}$, others are all $10e^{-6}$.
\end{table}

\subsection{Converge curves}

Our experiments are running on OS:$Win7$, 2 Inter Core $ i5\:$ CPU: $ 2.5GHz$, RAM: $4GB$, Language: $Matlab2012$. Fig.\ref{7} shows the converge curves of algorithms above. Although TLDE and NTLDE runs double basic DE in candidate layer, it still converge faster than jDE, SDE and JADE, the mutation strategy of JADE is differ from others which costs more time in each iteration.
\begin{figure}[htbp]
\centering
\includegraphics[width=8.5cm]{con80}
\caption{Converge curves of function 8} \label{7}
\end{figure}

Table below shows time consuming in function 8. The average time cost of TLDE is good enough with other self-adaptive DEs, while niching method calculating distance in each generation costs time, almost as twice consuming time as TLDE. Therefore, in general functions, the TLDE will be efficient enough to compute an acceptable optimum and the niching method is only required to optimize complex functions.

\begin{center}
\begin{tabular}{|c |c |c |c |c |c| }
\hline
\multicolumn{1}{|c|}{F8}
& \multicolumn{1}{c|}{JADE}
& \multicolumn{1}{c|}{jDE}
& \multicolumn{1}{c|}{SDE}
& \multicolumn{1}{c|}{TLDE}
& \multicolumn{1}{c|}{NTLDE}\\
 \hline
$time(s)$ &0.73 &0.50 &0.66 &0.53 &1.02\\
\hline
\end{tabular}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusions} \label{ch6}

In this paper, a clearing procedure of niching method is proposed to maintain the diversity of the population, and prevent the premature convergence to local optimal. we tried clearing niching method into DE mutation strategy to determine the set of target vectors, which acts an important role in evolution. In mutation strategy, target vectors are randomly chosen from the winner set cleared by niching method, step vectors are determined by two different methods respectively.\\

In the first proposal, a niche novelty metric is introduced to evaluate the degree of search space, which achieve a punishment mechanism to reduce the searching of overlap areas. Also, a Boltzmann scheme niche capacity selection is proposed to improve the performance by a balance searching between exploration and exploitation, where the power of searching is determined by the number of winners in niches. The results from twenty different functions shown that, comparing to the conventional DE, clearing niching with Boltzmann method realized a balance searching procedure in DE with a stable system insensitive to population size.\\

The second proposal presents an enhanced niching Two-Layered DE with self-adaptive control parameters, which eliminates the time consuming trial and error procedure for finding perfect parameters. In order to have more offspring to choose, with those control parameters, we doubled the basic DE process on each individual in population. A learning period in also proposed to judge the control parameters by the rate that successfully evolve the solution during the learning period. The modification is tested on commonly used benchmark problems for unconstrained optimization.\\

Empirical results indicates that the proposed niching mutation strategy with two-layer DE structured parameter control is competitive and very promising. It exhibits a robust and stable behavior during the optimal-searching procedure.

Future target is to extend current work and improve this system, the entry point may start from different mutation strategies instead of the original ``DE/rand/1/bin'' we applied in this paper.


\begin{appendices}

\renewcommand{\thechapter}{\Alph{chapter}.}

\chapter{Benchmark Functions}

To assure a fair comparison, twenty complicate benchmark functions from \cite{yao1999evolutionary}\cite{suganthan2005problem} are choose to test the performance of our proposed method. The benchmarks we adopt include several unimodal and multimodal functions, most of them have some global optima and many local optima in high dimension (30D) , which are difficult to find global minima especially shifted and rotated functions $f_{14}-f_{20}$. If the number of test problems were smaller, a general conclusion will be less convince. Using a test set with inadequate types of problems also exist a potential risk, that the out-coming good results may limited applicable to some unique problems. Such bias might not be useful for general optimization. Benchmark functions are shown in table \ref{Benchmark}, for a intuitive result, the global minima of all these functions are all set to $0$.

The first 13 functions are from Yao {\it et al.}'s proposal \cite{yao1999evolutionary}and the last 7 functions are from CEC 2005's proposal \cite{suganthan2005problem}. In order to evaluate the algorithm performance in different aspects, the test functions can be divided into three groups according to their different characteristics. functions $f_1-f_6$ are unimodal, while $f_7-f_{13}$ are multimodal functions, which are all difficult to be optimized because the number of local optima increases exponentially with the problem dimension. The third group includes the shifted and rotated functions $f_{14}-f_{20}$, which are taken from the CEC 2005's $f_6$ to $f_{10}$ \cite{suganthan2005problem}. These functions are chosen because thy are all difficult multimodal functions with the global optimal position shifted or the search variables rotated, or both.

Therefore, all these 20 functions are useful to test the global searching ability of the algorithms because they cover the different problem characteristics including unimodal, multimodal, separable, non-separable, shifted, and rotated. Detailed descriptions of each function is given in \cite{yao1999evolutionary}\cite{suganthan2005problem}. In this paper, all the functions are set as 30 dimensions. The search ranges, global optimal positions, and acceptable error values are adopted directly from the literature \cite{yao1999evolutionary}\cite{suganthan2005problem}.

\begin{table*}[tb]\footnotesize
 \renewcommand{\arraystretch}{0.6}
\caption{\large The twenty global optimization benchmark functions}
\begin{center}
\begin{tabular}{c c c c c c}
\hline
\multicolumn{1}{c}{Function}
& \multicolumn{1}{c}{Search Space}
& \multicolumn{1}{c}{Global Opt.x}
& \multicolumn{1}{c}{Global Min}
& \multicolumn{1}{c}{Accept}
& \multicolumn{1}{c}{Name}\\
\hline
 f1& $[-100,100]^D$ & $\{0\}^D$ & 0 & $1\times 10^{-6}$ &Sphere\cite{yao1999evolutionary}\\
 f2& $[-100,100]^D$ &$\{0\}^D$ &0 & $1\times 10^{-6}$ &Schwefel's2.21\cite{yao1999evolutionary}\\
 f3& $[-10,10]^D$ & $\{0\}^D$ & 0 & $1\times 10^{-6}$ &Schwefel's2.22\cite{yao1999evolutionary}\\
 f4& $[-100,100]^D$ & $\{0\}^D$ &0 & $1\times 10^{-6}$ &Quadric\cite{yao1999evolutionary}\\
 f5& $[-100,100]^D$ & $\{0\}^D$ &0 & 0 &Step\cite{yao1999evolutionary}\\
 f6&$[-1.28,1.28]^D$& $\{0\}^D$ &0 & $1\times 10^{-2}$ &Noise\cite{yao1999evolutionary}\\ \hline
 f7& $[-10,10]^D$   & $\{0\}^D$ &0 & $1\times 10^{-6}$ &Rosenbrock\cite{yao1999evolutionary}\\
 f8& $[-500,500]^D$ & $\{420.9687\}^D$ &0 & $1\times 10^{-2}$ &Schwefel\cite{yao1999evolutionary}\\
 f9&$[-5.12,5.12]^D$& $\{0\}^D$ &0 & $1\times 10^{-6}$ &Rastrigin\cite{yao1999evolutionary}\\
 f10& $[-32,32]^D$  & $\{0\}^D$ &0 & $1\times 10^{-6}$ &Ackley\cite{yao1999evolutionary}\\
 f11& $[-600,600]^D$& $\{0\}^D$ &0 & $1\times 10^{-6}$ &Griewank\cite{yao1999evolutionary}\\
 f12& $[-50,50]^D$  & $\{1\}^D$ & 0 & $1\times 10^{-6}$ &Generalized Penalized1.1\cite{yao1999evolutionary}\\
 f13& $[-50,50]^D$  & $\{1\}^D$ &0 & $1\times 10^{-6}$ &Generalized Penalized1.2\cite{yao1999evolutionary}\\
 \hline
 f14& $[-100,100]^D$ & o &390 & $1\times 10^{-2}$ &Shifted Rotated Rosenbrock\cite{suganthan2005problem}\\
 f15& $[-600,600]^D$ & o &-180 & $1\times 10^{-2}$ &Shifted Rotated Griewank\cite{suganthan2005problem}\\
 f16& $[-32,32]^D$ & o &140 & $1\times 10^{-2}$ & Shifted Rotated Ackley\cite{suganthan2005problem}\\
 f17& $[-5,5]^D$ & o &-330 & $1\times 10^{-2}$ &Shifted Rastrigin\cite{suganthan2005problem}\\
 f18& $[-5,5]^D$ & o &-330 & $1\times 10^{-2}$ & Shifted Rotated Rastrigin\cite{suganthan2005problem}\\
 f19& $[-0.5,0.5]^D$ & o &90 & $1\times 10^{-2}$ &Shifted RotatedWeierstrass\cite{suganthan2005problem}\\
 f20& $[-pi,pi]^D$ & o &-460 & $1\times 10^{-2}$ &Schwefel's2.13\cite{suganthan2005problem}\\ \hline
\end{tabular}
\label{Benchmark}
\end{center}
\footnotesize All the test functions are with dimension D-30. Search space cross a wide range from 1 to 1200. The $f_{14}$ to $f_{19}$ contains multiple individuals to the minima $f(x)$. Accept is the acceptable error within the predefined minima value in 50 independent runs.
\end{table*}

 For each of these functions, the goal is to find the global minimizer, formally defined as, given $f: D\to R$, $D = \prod\limits_{i=1}^d[a_i,b_i], a_i<b_i, i=1,2,\dots,d$, find $x^{\ast}\in R^D$ with $f(x^{\ast}\leq f(x))$. The follow functions are chosen:\\
\\
1. Sphere function, defined as $f_1(x)=\sum\limits_{i=1}^Dx_i^2$,

where $x^{\ast}=0$ and $f(x^{\ast})=0$ for$[-100,100]^D$.\\
\\
2. Schwefel's 2.21 function, defined as $f_2(x)=max_i(\lvert X_i\rvert,1\leq i\leq D)$,

where $x^{\ast}=0$ and $f(x^{\ast})=0$ for$[-100,100]^D$.\\
\\
3. Schewefel's 2.22 function, defined as $f_3(x)=\sum\limits_{i=1}^D\lvert x_i\rvert +\prod\limits_{i=1}^D\lvert X_i \rvert$,

where $x^{\ast}=0$ and $f(x^{\ast})=0$ for$[-10,10]^D$.\\
\\
4. Schewefel's 1.2 function, defined as
$f_4(x)=\sum\limits_{i=1}^D(\sum\limits_{j=1}^i x_i)^2$,

where $x^{\ast}=0$ and $f(x^{\ast})=0$ for$[-100,100]^D$.\\
\\
5. Step function, defined as
$f_5(x)=\sum\limits_{i=1}^D(\lvert x_i+0.5\rvert)^2$,

where $x^{\ast}=0$ and $f(x^{\ast})=0$ for$[-100,100]^D$.\\
\\
6. Step function, defined as
$f_6(x)=\sum\limits_{i=1}^Dix_i^4+rand(0,1)$,

where $x^{\ast}=0$ and $f(x^{\ast})=0$ for$[-1.28,1.28]^D$.\\
\\
7. Rosenbrock function, defined as
$f_7(x)=\sum\limits_{i=1}^{D-1}[100(x_{i+1}-x_i^2)^2+(x_i-1)^2]$,

where $x^{\ast}=0$ and $f(x^{\ast})=0$ for$[-10,10]^D$.\\
\\
8. Schewefel function, defined as
$f_8(x)=\sum\limits_{i=1}^D-x_isin(\sqrt{\lvert x_i\rvert}+418.9829\times D)$,

where $x^{\ast}=0$ and $f(x^{\ast})=0$ for$[-500,500]^D$.\\
\\
9. Rastrigin function, defined as
$f_9(x)=c[x_i^2-10cos(2\pi x_i)+10]$,

where $x^{\ast}=0$ and $f(x^{\ast})=0$ for$[-5.12,5.12]^D$.\\
\\
10. Ackley function, defined as
$f_{10}(x)=-20exp(-0.2\sqrt{\frac{1}{D}\sum\limits_{i=1}^Dx^2})-exp(\frac{1}{D}\sum\limits_{i=1}^Dcos2\pi x_i)+20+\epsilon$,

where $x^{\ast}=0$ and $f(x^{\ast})=0$ for$[-32,32]^D$.\\
\\
11. Grewank function, defined as
$f_{11}(x)=\frac{1}{4000}\sum\limits_{i=1}^D x_i^2-\prod\limits_{i=1}^Dcos(\frac{x_i}{\sqrt{i}}+1)$,

where $x^{\ast}=0$ and $f(x^{\ast})=0$ for$[-600,600]^D$.\\
\\
12. Generalized Penalized function, defined as

$f_{12}(x)=\frac{\pi}{D}{sin(\pi y_1)^2+\sum\limits_{i=1}^{D-1}(y_i-1)^2[1+10sin(\pi y_{i+1})^2]+(y_D-1)^2}+\sum\limits_{i=1}^Du(x_i,10,100,4)$,

where $y_i=1+\frac{1}{4}(x_i+1)$,
$u(x_i,a,k,m)=\left\{
\begin{array}{lll}
k(x_i-a)^m, \quad x_i>a\\
0,\quad -a \leq x_i \leq a\\
k(-x_i-a)^m, \quad x_i<-a
\end{array}
\right.$

where $x^{\ast}=0$ and $f(x^{\ast})=0$ for$[-50,50]^D$.\\
\\
13 Generalized Penalized function, defined as

$f_{13}(x)=0.1{sin(3\pi x_1)^2}+\sum\limits_{i=1}^{D-1}(y_i-1)^2[1+sin(3\pi x_{i+1})^2]+(x_D-1)[1+sin(2\pi x_D)^2]+\sum\limits_{i=1}^Du(x_i,5,100,4)$

where $y_i=1+\frac{1}{4}(x_i+1)$,
$u(x_i,a,k,m)=\left\{
\begin{array}{lll}
k(x_i-a)^m, \quad x_i>a\\
0,\quad -a \leq x_i \leq a\\
k(-x_i-a)^m, \quad x_i<-a
\end{array}
\right.$

where $x^{\ast}=0$ and $f(x^{\ast})=0$ for$[-50,50]^D$.\\
\\
14. Shifted Rotated Rosenbrock function, defined as

$f_{14}(x)=\sum\limits_{i=1}^{D-1}(100(z_{i+1}-z_i^2)^2+(x_i-1)^2)+f\_bias_6, z=(x-o)\ast M$,

the shifted global optimum: $o=[o_1,o_2,\dots,o_D]$, M: orthogonal matrix

where global optimum $x^{\ast}=o$ and $f(x^{\ast})=390$ for $[-100,100]^D$.\\
\\
15. Shifted Rotated Griewank function, defined as

$f_{15}(x)=\sum\limits_{i=1}^D\frac{z_i^2}{4000}-\prod\limits_{i=1}^Dcos(\frac{z_i}{\sqrt{i}})+f\_bias_7, z=(x-o)\ast M$,

the shifted global optimum: $o=[o_1,o_2,\dots,o_D]$, M: orthogonal matrix

where global optimum $x^{\ast}=o$ and $f(x^{\ast})=-180$ for $[-600,600]^D$.\\
\\
16. Shifted Rotated Griewank function, defined as

$f_{16}(x)=-20exp(-0.2\sqrt{\frac{1}{D}\sum\limits_{i=1}^Dx^2})-exp(\frac{1}{D}\sum\limits_{i=1}^Dcos2\pi x_i)+20+ e +f\_bias_8,z=(x-o)\ast M$,

the shifted global optimum: $o=[o_1,o_2,\dots,o_D]$, M: orthogonal matrix

where global optimum $x^{\ast}=o$ and $f(x^{\ast})=-140$ for $[-32,32]^D$.\\
\\
17. Shifted Rastrigin function, defined as

$f_{17}(x)=\sum\limits_{i=1}^D(z_i^2-10cos(2\pi z_i)+10)+f\_bias_9,z=(x-o)\ast M$,

the shifted global optimum: $o=[o_1,o_2,\dots,o_D]$, M: orthogonal matrix

where global optimum $x^{\ast}=o$ and $f(x^{\ast})=-330$ for $[-5,5]^D$.\\
\\
18. Shifted Rotated Rastrigin function, defined as

$f_{18}(x)=\sum\limits_{i=1}^D(z_i^2-10cos(2\pi z_i)+10)+f\_bias_{10},z=(x-o)\ast M$,

the shifted global optimum: $o=[o_1,o_2,\dots,o_D]$, M: orthogonal matrix

where global optimum $x^{\ast}=o$ and $f(x^{\ast})=-330$ for $[-5,5]^D$.\\
\\
19. Shifted Rotated Weierstrass function, defined as

$F_{19}(x)=\sum\limits_{i=1}^D(\sum\limits_{i=1}^{kmax}(a^kcos(2\pi b^k(z_i+0.5))))-\sum\limits_{i=1}^D(\sum\limits_{i=1}^{kmax}(a^kcos(2\pi b^k \cdot 0.5)))+f\_bias_{11},$

$a=0.5, b=3, kmax=20, z=(x-o)\ast M$,

the shifted global optimum: $o=[o_1,o_2,\dots,o_D]$, M: orthogonal matrix

where global optimum $x^{\ast}=o$ and $f(x^{\ast})=90$ for $[-0.5,0.5]^D$.\\
\\
20. Schwefel's 2.13 function, defined as
$f_{20}(x)=\sum\limits_{i=1}^D(A_i-B_i(x))^2+f\_bias_{12}$,

$A_i=\sum\limits_{i=1}^D(a_{ij}sin\alpha_i+b_{ij}cos\alpha_j)$,
$B_i(x)=\sum\limits_{i=1}^D(\alpha_{ij}sinx_j+b_{ij}cosx_j)$,
$\alpha=[\alpha_1,\alpha_2,\dots,\alpha_D]\in[-\pi,\pi]$,

where global optimum $x^{\ast}=\alpha $ and $f(x^{\ast})=460$ for $[-\pi,\pi]^D$.\\
\\

 \end{appendices}

\bibliographystyle{IEEEtran}
\bibliography{LUOreference}


\end{document}
