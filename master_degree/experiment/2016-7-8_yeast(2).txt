#日期：2016年7月8日

实验记录：

1，模型： 无边界检测，bagging训练样本，构造多个决策树，之后得到一个准线性核矩阵，生成一个QLSVM分类器。

2，对比分类器： RBFSVM , LinearSVM

3，数据集：yeast

4，实验总结：

5，实验结果： CV=None(shuffle=True), yeast=((625L, 436L)),
			  pos(class=2)=158,neg(others)=467

	1）RBF
		precision_score : 0.356164383562
		recall_score : 0.619047619048
		f1_score : 0.452173913043

		precision_score : 0.395161290323
		recall_score : 0.583333333333
		f1_score : 0.471153846154

		precision_score : 0.341772151899
		recall_score : 0.642857142857
		f1_score : 0.446280991736

	2）Linear
		precision_score : 0.414414414414
		recall_score : 0.547619047619
		f1_score : 0.471794871795

		precision_score : 0.333333333333
		recall_score : 0.642857142857
		f1_score : 0.439024390244

		precision_score : 0.367346938776
		recall_score : 0.642857142857
		f1_score : 0.467532467532

	3）QLinear
	myFore = my_RF_QLSVM.RF_QLSVM_clf(n_trees=30, 
	                    leafType='LogicReg', errType='lseErr_regul',
	                    max_depth=None, min_samples_split=5,
	                    max_features='log2',bootstrap_data=True)
	k=0.5
	X_delta = X - np.mean(X, axis=0)
	{0: array([ 9.        ,  0.41025641,  0.57142857,  0.47761194]),
	 1: array([ 13.        ,   0.41025641,   0.57142857,   0.47761194]),
	 2: array([ 18.        ,   0.4368932 ,   0.53571429,   0.48128342]),
	 3: array([ 23.        ,   0.42574257,   0.51190476,   0.46486486]),
	 4: array([ 27.        ,   0.4368932 ,   0.53571429,   0.48128342]),
	 5: array([ 32.        ,   0.40677966,   0.57142857,   0.47524752]),
	 6: array([ 37.        ,   0.43269231,   0.53571429,   0.4787234 ]),
	 7: array([ 41.        ,   0.41025641,   0.57142857,   0.47761194]),
	 8: array([ 46.        ,   0.43137255,   0.52380952,   0.47311828]),
	 9: array([ 51.        ,   0.43269231,   0.53571429,   0.4787234 ]),
	 10: array([ 55.        ,   0.4368932 ,   0.53571429,   0.48128342]),
	 11: array([ 60.        ,   0.41025641,   0.57142857,   0.47761194]),
	 12: array([ 65.        ,   0.41025641,   0.57142857,   0.47761194]),
	 13: array([ 69.        ,   0.40677966,   0.57142857,   0.47524752]),
	 14: array([ 74.        ,   0.40336134,   0.57142857,   0.4729064 ]),
	 15: array([ 79.        ,   0.40677966,   0.57142857,   0.47524752])}

 	myFore = my_RF_QLSVM.RF_QLSVM_clf(n_trees=30, 
                    leafType='LogicReg', errType='lseErr_regul',
                    max_depth=None, min_samples_split=5,
                    max_features='log2',bootstrap_data=True)
	k=1
	X_delta = X - np.mean(X, axis=0)

	{0: array([ 9.        ,  0.42201835,  0.54761905,  0.47668394]),
	 1: array([ 14.        ,   0.41818182,   0.54761905,   0.4742268 ]),
	 2: array([ 19.        ,   0.42201835,   0.54761905,   0.47668394]),
	 3: array([ 23.        ,   0.41441441,   0.54761905,   0.47179487]),
	 4: array([ 28.        ,   0.42201835,   0.54761905,   0.47668394]),
	 5: array([ 33.        ,   0.41904762,   0.52380952,   0.46560847]),
	 6: array([ 38.        ,   0.41509434,   0.52380952,   0.46315789]),
	 7: array([ 42.        ,   0.41071429,   0.54761905,   0.46938776]),
	 8: array([ 47.        ,   0.41441441,   0.54761905,   0.47179487]),
	 9: array([ 52.        ,   0.42201835,   0.54761905,   0.47668394]),
	 10: array([ 57.        ,   0.41509434,   0.52380952,   0.46315789]),
	 11: array([ 61.        ,   0.42201835,   0.54761905,   0.47668394]),
	 12: array([ 66.        ,   0.41509434,   0.52380952,   0.46315789]),
	 13: array([ 71.        ,   0.41747573,   0.51190476,   0.45989305]),
	 14: array([ 76.        ,   0.42201835,   0.54761905,   0.47668394]),
	 15: array([ 80.        ,   0.41441441,   0.54761905,   0.47179487])}